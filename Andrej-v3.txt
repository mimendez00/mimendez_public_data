Andrej Karpathy said "think it's possible that physics has exploits and we should be trying to find them. arranging some kind of a crazy quantum mechanical system that somehow gives you buffer overflow somehow gives you a rounding error and the floating point. Synthetic intelligences are kind of like the next stage of development. And I don't know where it leads to like at some point, I suspect the universe is some kind of a puzzle, these synthetic AIS will uncover that puzzle and solve it."
Lex Fridman said "The following is a conversation with Andrej Karpathy. Previously, the director of AI at Tesla. And before that, at open AI, and Stanford, he is one of the greatest scientists, engineers and educators in the history of artificial intelligence. This is the LEX Friedman podcast to support it, please check out our sponsors. And now, dear friends, here's Andrej Karpathy thing. What is a neural network? And why does it seem to do such a surprisingly good job of learning?"
Andrej Karpathy said "What is a neural network, it's a mathematical abstraction of the brain, I would say that's how it was originally developed. At the end of the day, it's a mathematical expression. And it's a fairly simple mathematical expression when you get down to it. It's basically a sequence of matrix multiplies whichever li dot products mathematically, and some non linearity is thrown in. And so it's a very simple mathematical expression. And it's got knobs in it many knobs, many knobs, and these knobs are loosely related to basically the synapses in your brain. They're trainable, they're modifiable. And so the idea is like, we need to find the setting of the knobs that makes the neural net, do whatever you want it to do, like classify images, and so on. And so there's not too much mystery, I was saying that like, you might think that basically don't want to endow it with too much meaning with respect to the brain and how it works. It's really just a complicated mathematical expression with knobs. And those knobs need a proper setting for it to do something desirable. Yeah, but poetry"
Lex Fridman said "is just a collection of letters with spaces, but it can make us feel a certain way. In that same way, when you get a large number of knobs together, whether it's in the inside the brain or inside a computer, they seem to. They seem to surprise us with the power."
Andrej Karpathy said "Yeah, I think that's fair. So basically, I'm underselling it by a lot, because you definitely do get very surprising emergent behaviors out of these neural nets when they're large enough and trained on complicated enough problems. Like say, for example, the next word prediction in a massive data set from the internet. And then these neural nets they call pretty surprising magical properties. Yeah, I think it's kind of interesting how much you can get out of even very simple mathematical formalism,"
Lex Fridman said "when your brain right now is talking. Is it doing next word prediction? Or is it doing something more interesting?"
Andrej Karpathy said "Well, definitely some kind of a generative model. That's a GPT. Like and prompted by you. Yeah. So you're giving me a prompt? And I'm kind of like responding to it in a generative way."
Lex Fridman said "And by yourself, perhaps a little bit? Like, are you adding extra prompts from your own memory inside your head?"
Andrej Karpathy said "Or no, definitely feels like you're referencing some kind of a declarative structure of like, memory, and so on. And then you're putting that together with your prompt and giving away some so"
Lex Fridman said "how much of what you just said, has been said by you before?"
Andrej Karpathy said "Nothing basically, right?"
Lex Fridman said "No, but if you actually look at all the words you've ever said in your life, and you do a search, you'll probably said, a lot of the same words in the same order before."
Andrej Karpathy said "Yeah, could be. I mean, I'm using phrases that are common, etc. But I'm really mixing it into a pretty sort of unique sentence at the end of the day. But you're right, definitely, there's like a ton of re mixing"
Lex Fridman said "why you, didn't you? It's like Magnus Carlsen said, I'm ready to 2900 Whatever, which is pretty decent. I think you're talking very, you're not giving enough credit to neural nets here. Why do they seem to work? What's your best intuition about this emergent behavior?"
Andrej Karpathy said "Um, it's kind of interesting, because I'm simultaneously underselling them. But I also feel like there's an element to which I'm over. Like, it's actually kind of incredible that you can get so much emergent magical behavior out of them, despite them being so simple mathematically. So I think those are kind of like two surprising statements that are kind of just juxtaposed together. And I think basically, what it is, is we are actually fairly good at optimizing these neural nets. And when you give them a hard enough problem, they are forced to learn very interesting solutions in the optimization. And those solution basically have these emergent properties that are very interesting."
Lex Fridman said "There's wisdom and knowledge in the knobs, and so on. Yes, this representation that's in the knobs doesn't make sense to you intuitively, the large number of knobs can hold a representation that captures some deep wisdom about the data. It has looked at a lot of knobs."
Andrej Karpathy said "It's a lot of knobs And somehow, you know, so speaking concretely, one of the neural nets that people are very excited about right now are our GPS, which are basically just next word prediction networks. So you consume a sequence of words from the internet, and you try to predict the next word. And once you train these on a large enough data set, they, you can basically prompt these neural nets in arbitrary ways. And you can ask them to solve problems, and they will. So you can just tell them, you can, you can make it look like you're trying to solve some kind of a mathematical problem. And they will continue to do what they think is the solution based on what they've seen on the internet. And very often, those solutions look very remarkably consistent look correct, potentially."
Lex Fridman said "Do you still think about the brain side of it? So as neural nets is an abstraction or mathematical abstraction of the brain, these still draw wisdom from, from the biological neural networks are even the bigger question. So you're a big fan of biology and biological computation. What impressive thing is biology do doing to you that computers are not yet that gap,"
Andrej Karpathy said "I would say I'm definitely on a much more hesitant with the analogies to the brain than I think you would see potentially in the field. And I kind of feel like, certainly, the way neural networks started is everything stemmed from inspiration of the brain, but at the end of the day, the artifacts that you get after training, they are arrived at by a very different optimization process than the optimization process that gave rise to the brain. And so I think, I kind of think of it as a very complicated alien artifact, it's something different, doesn't necessarily the, the neural nets that we're training, okay, they are complicated alien artifact, I do not make analogies to the brain, because I think the optimization process that gave rise to it is very different from the brain. So there was no multi agent self play kind of setup, and evolution, it was an optimization, that is basically a what amounts to a compression objective on a massive amount of data."
Lex Fridman said "Okay, so artificial neural networks are doing compression, and biological neural networks are to survive. And by really doing a they're, they're an agent in a multi agent, self play system that has been running for a very, very long time."
Andrej Karpathy said "That said, evolution has found that it is very useful to, to predict and have a predictive model in the brain. And so I think our brain utilizes something that looks like that as a part of it. But it has a lot more, you know, couches and gizmos, and value functions and ancient nuclei that are all trying to like make us survive and reproduce and everything else."
Lex Fridman said "And the whole thing through embryogenesis is built from a single cell. I mean, it's just the code is inside the DNA. And it just builds it up like the entire organism with"
Andrej Karpathy said "crazy head"
Lex Fridman said "and legs. Yes. And like"
Andrej Karpathy said "it's does it pretty well. It may not be possible."
Lex Fridman said "So there's some learning going on. There's some there's some there's some kind of competition going through that building process. I mean, I don't know where if you're just the look at the entirety of history of life on Earth, what do you think is the most interesting invention? Is it the origin of life itself? Is it just jumping to eukaryotes? Is it mammals? Is a humans themselves almost Sapiens, the origin of intelligence or highly complex intelligence? Or? Or is it all just a continuation of the same kind of process?"
Andrej Karpathy said "Certainly, I would say it's an extremely remarkable story that I'm only like briefly learning about recently, all the way from actually like, you almost have to start at the formation of earth, and all of its conditions and the entire solar system and how everything is arranged with Jupiter and Moon and the habitable zone and everything. And then you have an active earth that's turning over material. And then you start with a view about Genesis and everything. And so it's all like a pretty remarkable story. I'm not sure that I can pick like a single unique piece of it, that I find most interesting. I guess for me, as an artificial intelligence researcher, it's probably the last piece we have lots of animals that, you know, are, are not building technological society. But we do. And it seems to have happened very quickly. It seems to have happened very recently. And something very interesting happened there that I don't fully understand. I almost understand everything else, kind of I think intuitively. But I don't understand exactly that part. And how quick that was."
Lex Fridman said "Both explanations will be interesting. One is that this is just a continuation of the same kind of process. There's nothing special about humans, that will be deeply understanding that will be very interesting that we think of ourselves as special but it was obvious all it was already written in, in the code that you would have greater and greater until just emerging. And then the other explanation, which is something truly special happened something like a rare event, whether it's like crazy rare event like Space Odyssey, what would it be? See if you say like the invention of fire, or the, as Richard Wrangham says the beta males deciding a clever way to kill the alpha males by collaborating, so just optimizing the collaboration, the really the multi agent aspects of the multi agent, and that really being constrained on resources and trying to survive. The collaboration aspect is what created the complex intelligence. But it seems like it's a natural outgrowth of the evolution process. What could possibly be a magical thing that happened? Like a rare thing that would say that humans are actually human level intelligence is actually a really rare thing in the universe?"
Andrej Karpathy said "Yeah, I'm hesitant to say that it is rare, by the way, but it definitely seems like it's kind of like a punctuated equilibrium where you have lots of exploration, and then you have certain leaps, as far as leaps in between. So of course, like origin of life would be one, you know, DNA, sex, eukaryotic systems, eukaryotic life, the endosymbiosis event or the archaeon, eight little bacteria, you know, just the whole thing. And then, of course, the emergence of consciousness and so on. So it seems like different to that are sports events where massive amount of progress was made? But yet, it's kind of hard to pick one?"
Lex Fridman said "Do you don't think humans are unique, that I asked you? How many intelligent alien civilizations do you think are out there? And is their intelligence different or similar to ours?"
Andrej Karpathy said "Yeah, I've been preoccupied with this question quite a bit recently, basically, the Fermi paradox and just thinking through and and the reason, actually, that I am very interested in the origin of life is fundamentally trying to understand how common it is that there are technological societies out there in space, and the more I study it, the more I think that there should be quite a few, quite a lot."
Lex Fridman said "Why haven't we heard from them, because I agree with you, it feels like, I just don't see why the what we did here on Earth is so difficult to do."
Andrej Karpathy said "Yeah, and especially when you get into the details of it, I used to think origin of life was very, it was this magical rare event, but then you read books, like, for example, in the clean, the vital question, whole life ascending, etc. And he really gets in. And he really makes you believe that this is not that rare, basic chemistry, you have an active earth, and you have your alkaline vents, and you have lots of alkaline water mixing, whether it's a devotion, and you have your proton gradients, and you have the global powers pockets of these Klein vents that concentrate chemistry. And basically, as he steps through all of these little pieces, you start to understand that, actually, this is not that crazy, you could see this happen on other systems. And he really takes you from just a geology to primitive life. And he makes it feel like it's actually pretty plausible. And also, like the origin of life didn't was actually fairly fast after formation of Earth. If I remember correctly, just a few 100 million years for something like that after basically when it was possible life actually arose. So that makes me feel that that is not the constraint, that is not the limiting variable, and that life should actually be fairly common. And then you know, where the drop offs are, is very, is very interesting to think about. I currently think that there's no major drop offs, basically. And so there should be quite a lot of life. And basically, what we're that brings me to then is the only way to reconcile the fact that we haven't found anyone and so on is that we just can't we can't see them. We can't observe them."
Lex Fridman said "Just a quick brief comment, Nick lane, and a lot of biologists I talked to, they really seem to think that the jump from bacteria to more complex organisms is the hardest"
Andrej Karpathy said "jump. The eukaryotic life. Yes. Yeah. Which"
Lex Fridman said "I don't I get it. They're much more knowledgeable than me about like the intricacies of biology. But that seems like crazy, because how much how many single celled organisms are there? Like and how much time you have? Surely, it's not that difficult. Like in a billion years. It's not even that long. Of a time really, just all these bacteria under constrained resources, battling it out. I'm sure they can invent more complex. I don't understand. It's like, how to move from a Hello World program to like, like, invent a function or something like that. I don't. Yeah. So I don't Yeah, so I'm with you. I just feel like I don't see any. If the origin of life, that will be my intuition. That's the hardest thing. But if that's not the hardest thing, because it happened so quickly, then it's got to be everywhere. And yeah, maybe we're just too dumb to see it"
Andrej Karpathy said "was just we don't have really good mechanisms for seeing this life. I mean, by what How. So I'm not an expert just to preface this, but just from what I"
Lex Fridman said "was, I want to meet an expert on alien intelligence and how to communicate, I'm"
Andrej Karpathy said "very suspicious of our ability to find these intelligences out there. And to find these Earth, like radio waves, for example, are are terrible, their power drops off as basically one over r square. So I remember reading that are current radio waves, but not be the ones that we are broadcasting would not be measurable by our devices today, only like was it like 1/10 of a light year away, like not even basically tiny distance, because you really need like a targeted transmission of massive power directed somewhere for this to be picked up on Long, long distances. And so I just think that our ability to measure is, is not amazing. I think there's probably other civilizations out there. And then the big question is, why don't they build von Neumann probes? And why don't they interstellar travel across the entire galaxy? And my current answer is, it's probably interstellar travel is like really hard. You have the interstellar medium, if you want to move at close to the speed of light, you're going to be encountering bullets along the way. Because even like tiny hydrogen atoms and little particles of dust are basically we have like massive kinetic energy at those speeds. And so basically, you need some kind of shielding, you need, you have all the cosmic radiation. It's just like brutal out there. It's really hard. And so my thinking is, maybe interstellar travel is just extremely hard."
Lex Fridman said "I think you have two years to build hard. It feels like, it feels like we're not a billion years away from doing that,"
Andrej Karpathy said "it just might be that it's very, you have to go very slowly, potentially, as an example, through space, right, as opposed to close to the speed of light. So I'm suspicious basically, of our ability to measure life. And I'm suspicious of the ability to just permeate all of space in the galaxy or across galaxies. And that's the only way that I can, I can currently see a way around it."
Lex Fridman said "It's kind of mind blowing to think that there's trillions of intelligent alien civilizations out there, kind of slowly traveling through space made to meet each other and some of them meet. Some of them go to war, some of them collaborate."
Andrej Karpathy said "And more. They're all just independent, just like little pockets."
Lex Fridman said "For statistically, if there's like, emphasis trillions of them, surely some of them, some of the pockets are close enough to get some of them happen to be close. enough, close enough to see each other. And then once you see once you see something that is definitely complex life, like if we see something, yeah, we're probably going to be severe, like intensely aggressively motivated to figure out what the hell that is, and try to meet them. But what will be your first instinct to try to, like at a generational level, meet them? Or defend against them? Or what would be your instinct, as a President of the United States? And the scientists? I don't know which hat you prefer in this question."
Andrej Karpathy said "Yeah, I think the question, it's really hard. I will say like, for example, for us, we have lots of primitive life forms on Earth. Next to us, we have all kinds of ants and everything else, and we share space with them. And we are hesitant to impact on them and to we are trying to protect them by default. Because they are amazing, interesting dynamical systems that took a long time to evolve. And they are interesting and special. And I don't know that you want to destroy that by default. And so I like complex dynamical systems that took a lot of time to evolve, I think I'd like to, I like to preserve it, if I can afford to. And I'd like to think that the same would be true about the galactic resources, and that, they would think that we're kind of incredible, interesting story that took time, it took a few billion years to unravel, and you don't want to just destroy it,"
Lex Fridman said "I can see two aliens talking about Earth right now and saying, I'm a big fan of complex dynamical systems. So I think it was a value to preserve these who basically are a video game they watch or show a TV show that they watch."
Andrej Karpathy said "Yeah, I think you need like a very good reason, I think to, to destroy it. Like, why don't we destroy these and farms and so on? It's because we're not actually like, really in direct competition with them right now. We do it accidentally, and so on, but there's plenty of resources. And so why would you destroy something that is so interesting and precious?"
Lex Fridman said "Well, from a scientific perspective, you might probe it, you might interact with it, you might want to learn something from it, right? So I wonder there's could be certain physical phenomena that we think is a physical phenomena, but it's actually interacting with us to like, poke the finger and see what happens. I think it"
Andrej Karpathy said "should be very interesting to scientists, other alien scientists what happened here. And you know, it's a, what we're seeing today is a snapshot. Basically, it's a result of a huge amount of computation of over like billing years or something like that. So"
Lex Fridman said "it could have been initiated by aliens. This could be a computer running a program, like when, okay, if you had the power to do this well When you okay, for sure, at least I would, I would pick an Earth like planet that has the conditions based my understanding of the chemistry prerequisites for life. And I would see them with life and run it. Right? Like yeah, when do you want 100%? Do that and observe it and then protect? I mean that that's not just a hell of a good TV show. It's it's a good scientific experiment. Yeah. And that is its physical simulation, right? What maybe, maybe the evolution is the most like actually running it is the most efficient way to understand computation or to compute stuff, or to understand"
Andrej Karpathy said "life, or, you know, what life looks like, and what branches it can take."
Lex Fridman said "That doesn't make me kind of feel weird that we're part of a science experiment, but maybe it's everything's a science experiments. Does that change anything for us? For a science experiment? To descendants of apes talking about being inside of the sun?"
Andrej Karpathy said "I'm suspicious of this idea of like, deliberate panspermia, as you would describe that service. And I don't see a divine intervention in some way. In the in the historical record right now. I do feel like the story in these in these books, like necklines books, and so on sort of makes sense. And it makes sense how life arose on Earth uniquely. And yeah, I don't need to, I mean, I don't need to reach for more exotic explanations right now. Sure. But NPCs"
Lex Fridman said "inside of video game, don't. Don't don't observe any divine intervention, either. We might just be all NPCs or any kind of code. Maybe"
Andrej Karpathy said "eventually, they will currently NPCs are really dumb. But once they're running GPS, maybe they will be like, Hey, this is really suspicious. What the hell."
Lex Fridman said "So you famously tweeted, it looks like if you bombard Earth with photons for a while, you can emit a roadster. So if like an Hitchhiker's Guide to the Galaxy, we would summarize the story of Earth. So in that book, it's mostly harmless. What do you think is all the possible stories, like a paragraph long or sentence long? That Earth could be summarized? As at once it done its computation? So like, all the possible full? If Earth is a book, right, yeah. Probably there has to be an ending. I mean, there's going to be an end to Earth, and we could end in all kinds of ways you can end soon you can then later, what do you think are the possible stories? Well, definitely,"
Andrej Karpathy said "there seems to be, yeah, you're sort of, it's pretty incredible that the self replicating systems will basically arise from the dynamics, and then they perpetuate themselves and become more complex and eventually become conscious and build a society. And I kind of feel like, in some sense, it's kind of like, a deterministic wave, that, you know, that kind of just like happens on any, you know, any sufficiently well arranged system like Earth. And so I kind of feel like there's a certain sense of inevitability in it. And it's really beautiful."
Lex Fridman said "And it ends somehow, right? So it's a, it's a chemically, a diverse environment, where complex dynamical systems can evolve and become more and more further and further complex. But then there's a certain what is it? There's certain terminating conditions?"
Andrej Karpathy said "You guys don't know what the terminating conditions are. But definitely, there's a trend line of something. And we're part of that story. And like, where does that where does it go? So, you know, we're famously described often as a biological bootloader for AI. And that's because humans, I mean, you know, we're an incredible biological system, and we're capable of computation, and, you know, and love and so on. But we're extremely inefficient as well, like we're talking to each other through audio, it's just kind of embarrassing, honestly, that we're manipulating like seven symbols serially, we're using vocal cords, it's all happening over like multiple seconds. It's just like kind of embarrassing when you step down to the frequencies at which computers operate, or are able to cooperate on And so basically, it does seem like synthetic intelligences are kind of like the next stage of development. And I don't know where it leads to like, at some point, I suspect the universe is some kind of a puzzle. And these synthetic AIS will uncover that puzzle and solve it."
Lex Fridman said "And then what happens after right like what because if you just like Fast Forward Earth, many buildings yours, it's like, it's quiet. And then it's like, turmoil you see like city lights and stuff like that. And then what happens at like at the end like is it like a? It's like a calming, is it explosion? Is it like Earth like open like a giant because you said omit roaster roasters, it was start emitting like, like a giant number of like satellites."
Andrej Karpathy said "Yes, some kind of a crazy explosion and we're living. We're like We're stepping through a explosion. And we're like living day to day and doesn't look like it. But it's actually if you I saw a very cool animation of Earth, and life on Earth, and basically nothing happens for a long time. And then the last like two seconds, like basically cities and everything. And the low Earth orbit just gets cluttered. And just the whole thing happens in the last few seconds. And you're like, This is exploding. Statement explosion."
Lex Fridman said "So if you play yeah, if you play at a normal speed, yeah, it'll just look like an explosion."
Andrej Karpathy said "It's a firecracker. We're living in a firecracker where it's"
Lex Fridman said "going to start emitting all kinds of interesting things. Yeah. And then the explosion doesn't, it might actually look like a little explosion, with with lights and fire and energy emitted all that kind of stuff. But when you look inside the details of the explosion, there's actual complexity happening, where there's like, yeah, human life or some kind of life."
Andrej Karpathy said "We hope it's not destructive firecracker, it's kind of like a constructive firecracker."
Lex Fridman said "Alright, so given that, I think, hilarious, this guy does"
Andrej Karpathy said "a really interesting thing about like, what the puzzle of the universe is, did the creator of the universe, give us a message, like, for example, in the book, contact, Carl Sagan, there's a message for humanity, for any civilization in the digits in the expansion of pi and base 11, eventually, just kind of interesting thought, maybe, maybe we're supposed to be giving a message to our Creator, maybe we're supposed to somehow create some kind of a quantum mechanical system that alerts them to our intelligent presence here. Because if you think about it, from their perspective, it just say like quantum field theory, massive like cellular automaton like thing, and like, how do you even notice that we exist, you might not even be able to pick us up in that simulation? And so how do you? How do you prove that you exist, that you're intelligent, and that you're part of the universe?"
Lex Fridman said "So this is like a Turing test for intelligence from Earth creators. I mean, maybe this is like trying to complete the next word in the sentence, this is a complicated way of that, like Earth is just is basically sending a message back."
Andrej Karpathy said "Yeah, the puzzle is basically like alerting the creator that we exist. Or maybe the puzzle is just to just break out of the system and just, you know, stick it to the creator in some way. Basically, like, if you're playing a video game, you can, you can somehow find an exploit and find a way to execute on the host machine. any arbitrary code. There's some, for example, I believe someone got Mario again with Mario to play Pong, just by exploiting it, and then creating a physical writing writing code and, and being able to execute arbitrary code in the game. And so maybe we should be maybe that's the puzzle is that we should be find a way to exploit it. So. So I think like some of these synthetic guys will eventually find the universe to be some kind of a puzzle, and then solve it in some way. And that's kind of like the end game somehow."
Lex Fridman said "Do you often think about it as, as a simulation? So as or the universe being a kind of computation that has might have bugs and exploits?"
Andrej Karpathy said "Yes. Yeah, I think so. Isaac, physics is essential. I think it's possible that physics has exploits. And we should be trying to find them. arranging some kind of a crazy quantum mechanical system that somehow gives you buffer overflow, somehow gives you a rounding error and a floating point."
Lex Fridman said "Yeah, that's right. And more like more and more sophisticated exploits, like these are jokes, but could be actually"
Andrej Karpathy said "find some way to extract an infinite energy. For example, when you train reinforcement learning agents, and physical simulations, and you ask them to say run quickly on the flat ground, they'll end up doing all kinds of like weird things. In part of that optimization, right? They'll get on their backlog, and they'll slide across the floor. And it's because of the optimization. The enforcement learning optimization on that agent has figured out a way to extract infinite energy from the friction forces and basically their poor implementation. And they found a way to generate infinite energy and just slide across the surface. And it's not what you expected. It's just a sort of like a perverse solution. And so maybe we can find something like that. Maybe we can be that little dog in this physical simulation, the"
Lex Fridman said "cracks or escapes the intended consequences of the physics that universe came up with. Yeah, we'll figure out some kind of shortcut to some weirdness. Yeah, and then see the problem. That weirdness is the first person to discover the weirdness, like sliding in the back legs. That's all we're gonna do. Yeah, it's very quickly because everybody does that thing. So, like, the paperclip, maximizer is a ridiculous idea, but that very well. Could be what then we'll just we'll just all swish that, because it's so fun."
Andrej Karpathy said "Well, no person will discover it. I think, by the way, I think it's going to have to be some kind of super intelligent AGI of a third generation. Like we're building the first generation AGI and you know,"
Lex Fridman said "third generation, yeah, so the bootloader for an AI that AI will be a bootloader for another AI Yeah. And then there's no way for us to introspect, like what No, then"
Andrej Karpathy said "I think it's very likely that these things, for example, like say you have these AGI, it's very likely that, for example, they will be completely inert. I like these kinds of sci fi books sometimes where these things are just completely ignored. They don't interact with anything. And I find that kind of beautiful, because they probably, they've probably figured out the meta meta game of the universe in some way. Potentially. They're, they're doing something completely beyond our imagination. And they don't interact with simple chemical life forms. Like, why would you do that? So I find those kinds of ideas compelling,"
Lex Fridman said "what's their source of fun? What are they? What are they doing?"
Andrej Karpathy said "What's the planet solving in the universe,"
Lex Fridman said "but in NERT, so can you define what it means in Earth today escape the interaction,"
Andrej Karpathy said "as in they will behave in some very, like strange way to us, because they're beyond, they're playing the mental game. And the mental game is probably say, like arranging quantum mechanical systems in some very weird ways to extract infinite energy, solve the digital expansion of pi to whatever amount, they will build their own, like little fusion reactors or something crazy. Like they're doing something beyond comprehension, and not understandable to us. And actually brilliant under the hood."
Lex Fridman said "What if quantum mechanics itself is the system and we're just thinking, It's physics. But we're really parasites on or not parasite, we're not really hurting physics. We're just living on this organisms, this organism and we're like, trying to understand it, but really, it is an organism. And with a deep, deep intelligence, maybe physics itself, is the organism that's doing the super interesting thing. And we're just like, one little thing. Yeah. And sitting on top of it, trying to get energy from it. We're just"
Andrej Karpathy said "kind of like these particles in the wave that I feel like is mostly deterministic and takes universe from some kind of a big bang to some kind of a super intelligent replicator, some kind of a stable point in the universe, given these laws of physics,"
Lex Fridman said "you don't think, as Einstein said, God doesn't play dice. So you think it's mostly deterministic? There's no randomness in the thing I think is"
Andrej Karpathy said "deterministic. Oh, there's tons of well, I want to be careful with randomness. pseudo random. A, I don't like random. I think maybe the laws of physics are deterministic. Yeah, I think their determination just"
Lex Fridman said "got really uncomfortable with this question. Do you have anxiety about whether the universe is random or not? This is?"
Andrej Karpathy said "What's there's no randomness? It's,"
Lex Fridman said "you see, you like Goodwill Hunting? It's not your fault, Andre? It's a fault, man. So you don't like randomness?"
Andrej Karpathy said "Yeah, I think it's unsettling. I think it's so deterministic system. I think that things that look random, like say, the collapse of the wavefunction, etc. I think they're actually deterministic, just entanglement and so on. And some kind of a multiverse theory something something."
Lex Fridman said "Okay, so why does it feel like we have a free will? Like, if I if I raised his hand, I chose to do this now. What? That doesn't feel like a deterministic thing. It feels like I'm making a choice. It feels like it. Okay, so it's all feelings. It's just feelings. Yeah. So when RL agent is making a choice is that that's not really making a choice. That choice was all already that"
Andrej Karpathy said "yeah, you're interpreting the choice. And you're creating a narrative for for having made it? Yeah."
Lex Fridman said "And now we're talking about the narrative. It's very meta. Looking back, what is the most beautiful or surprising idea in deep learning or AI, in general that you've come across, you've seen this field explode, and grow in interesting ways. Just what what cool ideas like, like waste made you sit back and go smart, big or small?"
Andrej Karpathy said "Well, the one that I've been thinking about recently, the most probably is the, the transformer architecture. So basically, neural networks have a lot of architectures that were trendy have come and gone for different sensory modalities, like for vision, audio text, you would process them with different looking neural nets. And recently, we've seen these, this convergence towards one architecture, the transformer, and you can feed it video or you can feed it, you know, images or speech or text and it just gobbles it up. And it's kind of like a bit of a general purpose computer. There's also trainable and very efficient to run on our hardware. And so this paper came out in 2016. I want to say,"
Lex Fridman said "attention is all you need attention is all you need. You criticize the paper title in retrospect, that it wasn't it didn't foresee the bigness of the impact that it was going to have you"
Andrej Karpathy said "I'm not sure if the authors were aware of the impact that that paper would go on to half probably weren't, but I think they were aware of some of the motivations and design decisions behind the transformer and they chose not to, I think expand and that way in the paper, and so I think they had an idea that there was more than just the surface of just like overages during translation. And here's a bit of architecture, you're not just doing translation. This is like a really cool differentiable optimizable efficient computer that you've proposed. And maybe they didn't have all of that foresight, but I think is really interesting."
Lex Fridman said "Isn't it funny Sorry to interrupt the that title is memorable that they went for such a profound idea. They went with a I don't think anyone use that kind of title before, right?"
Andrej Karpathy said "Attention is all you need. Yeah, it's like a meme or something. Yeah."
Lex Fridman said "It's not funny. That one. Like, maybe it was a more serious talent. Yeah. Now the impact?"
Andrej Karpathy said "Honestly, I yeah, there is an element of me that honestly agrees with you and prefers it this way? Yes. If it was two grand it would over promise and under deliver potentially. So you want to just mean your way to greatness."
Lex Fridman said "As you'd be a t shirt. So you you tweeted the transformers and magnificent neural network architecture, because it is a general purpose differentiable computer, it is simultaneously expressive in the forward pass optimizable via proper backpropagation, gradient descent and efficient, high parallelism, compute graph, can you discuss some of those details expressive optimizable. Efficient? Yeah, from memory or, or in general, whatever comes to your heart,"
Andrej Karpathy said "you want to have a general purpose computer that you can train on arbitrary problems, like say the task of next word prediction, or detecting if there's a cat in the image or something like that. And you want to train this computer, so you want to set its weights. And I think there's a number of design criteria that sort of overlap in the transformer simultaneously, that made it very successful. And I think the authors were kind of deliberately trying to make this really powerful architecture. And so it basically it's very powerful in the forward pass, because it's able to express very general computation as a sort of something that looks like message passing, you have nodes, and they all store vectors. And these nodes get to basically look at each other. And it's each other's vectors. And they get to communicate. And basically nodes get to broadcast, hey, I'm looking for certain things. And then other nodes get to broadcast Hey, these are the things I have, those are the keys and values. So it's not just attention. Yeah, exactly, transformer is much more than just the attention component. It's got many pieces architectural, that went into it, the residual connection of the way it's arranged, there's a multi layer perceptron in there, the way it's a stack, and so on. But basically, there's a message passing scheme where nodes get to look at each other, decide what's interesting, and then update each other. And so I think the, when you get to the details of it, I think it's a very expressive function. So it can express lots of different types of algorithms and forward paths. Not only that, but the way it's designed with the residual connections, layer normalizations, the softmax, attention and everything. It's also optimizable, this is a really big deal. Because there's lots of computers that are powerful that you can optimize. Or they're not easy to optimize using the techniques that we have, which is back propagation and gradient descent, these are first order methods, very simple optimizers, really, and so you also need it to be optimizable. And then lastly, you want it to run efficiently on our hardware, our hardware is a massive throughput machine, like GPUs, they prefer lots of parallelism. So you don't want to do lots of sequential operations, you want to do a lot of operations serially, and the transformer is designed with that in mind as well. And so it's designed for our hardware, and it's designed to both be very expressive in a forward pass, but also very optimizable in the backward pass."
Lex Fridman said "And you said that the residual connections support a kind of ability to learn short algorithms fast and first and then gradually extend them longer during training, what's what's the idea of learning short algorithms,"
Andrej Karpathy said "right? Think of it as so basically, a transformer is a series of blocks, right, and these blocks have attention and a little multi layer perceptron. And so you, you go off into a block, and you come back to this residual pathway, and then you go off and you come back, and then you have a number of layers arranged sequentially. And so the way to look at it, I think, is because of the residual pathway in the backward pass, the gradients sort of flow along it uninterrupted, because addition distributes the gradient equally to all of its branches. So the gradient from the supervision at the top, just floats directly to the first layer. And the all the residual connections are arranged so that in the beginning, during initialization, they contributed nothing to the residual pathway. So what this kind of looks like is imagine the Transformers kind of like a Python function like a def. And you get to do various kinds of lines of code. So you have 100, layers deep transformer, typically they will be much shorter, say 20. So if 20 lines of code, then you can do something in them. And so think during the optimization, basically, what it looks like is first you optimize the first line of code, and then the second line of code can kick in. And the third line of code can can and I kind of feel like because of the residual pathway and the dynamics of the optimization. You can sort of learn a very short algorithm that gets the approximate answer, but then the other layers can sort of kick in and start to create a contribution. And at the end of the year, you're optimizing over an algorithm that is 20 lines of code. Except these lines of code are very complex because it's an entire block of a transformer you can do a lot in there. Well, it's really interesting is that this transformer architecture actually has been remarkably resilient. Basically, a transformer that came out in 2016 is the transformer you would use today except you reshuffle some Boolean norms. There really are normalizations have been reshuffled to a pre norm formulation. And so it's been remarkably stable. But there's a lot of bells and whistles that people have attached to it and try to improve it. I do think that basically, it's a it's a big step in simultaneously optimizing for lots of properties of a desirable neural network architecture. And I think people have been trying to change it, but it's proven remarkably resilient. But I do think that there should be even better pictures potentially."
Lex Fridman said "But it's your you admire the resilience here. Yeah, there's something profound about this architecture that that least, maybe we can, everything can be turned into. into a problem that transformers can solve"
Andrej Karpathy said "currently definitely looks like the Transformers taking over AI. And you can feed basically arbitrary problems into it. And it's a general differentiable computer. And it's extremely powerful. And this convergence in AI has been really interesting to watch. For me personally."
Lex Fridman said "What else do you think could be discovered here about transformers? Like what surprising thing? Or is it a stable? I wouldn't a stable place, there's something interesting, we might discover about transformers, like aha moments maybe has to do with memory, maybe knowledge representation, that kind of stuff?"
Andrej Karpathy said "Definitely does that guys today is just pushing, like, basically, right now these guys do not touch the transformer, and touch everything else. Yes. So people are scaling up the datasets making them much, much bigger. They're working on the validation, making the evaluation much, much bigger. And they're basically keeping the architecture unchanged. And that's how we've done the last five years of progress in AI, kind of,"
Lex Fridman said "what do you think about one flavor of it? Which is language models? Have you been surprised? has years of imagination been captivated by you mentioned GPT, and all the bigger and bigger and bigger language models? And what are the limits? Of those models? Do you think? So just the task of natural language."
Andrej Karpathy said "Basically, the way GPT is trained, right, as you just don't a mass amount of text data from the internet. And you try to predict the next word in a sequence, roughly speaking, you're predicting little word chunks. But roughly speaking, that's it. And what's been really interesting to watch is, basically, it's a language model language models have actually existed for a very long time. There's papers on language modeling from 2003, even earlier,"
Lex Fridman said "can you explain that case? What language model is,"
Andrej Karpathy said "yeah, so language model, just basically, the rough idea is just predicting the next word in the sequence, roughly speaking. So there's a paper from for example, Bengio, and the team from 2003, where for the first time, they were using a neural network to take say, like three or five words and predict the next word, and they're doing this on much smaller datasets, and the neural net is not a transformer. It's a multi layer perceptron. But it's the first time that a neural network has been applied in that setting. But even before neural networks, there were language models, except they were using Engram models. So Engram models are just count based models. So if you try to, if you start to take two words and predict the third one, you just count up how many times you've seen any two word combinations and what came next. And what you predict is coming next is just what you've seen the most often the training set. And so luxury modeling has been around for a long time, neural networks have done language modeling for a long time. So really, what's new or interesting or exciting is just realizing that when you scale it up with a powerful enough neural net transformer, you have all these emergent properties, where basically what happens is, if you have a large enough data set of text, you are in the task of predicting the next word, you are multitasking, a huge amount of different kinds of problems. You are multitasking, understanding of, you know, chemistry, physics, human nature, lots of things are sort of clustered in that objective. It's a very simple objective. But actually, you have to understand a lot about the world to to make that prediction."
Lex Fridman said "You just said the EU word understanding. Are you in terms of chemistry, and physics and so on? What do you feel like it's doing is it's searching for the right context? In like, what is it? What is the actual process happening here?"
Andrej Karpathy said "Yes. So basically, it gets 1000 words and is trying to predict the 1000. And first, and in order to do that very, very well over the entire data set available on the internet, you actually have to basically kind of understand the context of, of what's going on in there. Yeah. And it's a sufficiently hard problem that you if you have a powerful enough computer, like a transformer, you end up with interesting solutions. And you can ask it to I'll do all kinds ends of things. And it shows a lot of emergent properties like in context learning, that was the big deal with GPT. And the original paper when they published it is that you can just sort of prompt it in various ways and ask it to do various things. And it will just kind of complete the sentence. But in the process of just completing the sentence, it's actually solving all kinds of really interesting problems that we care about."
Lex Fridman said "Do you think he's doing something like understanding, like, and when we use the word understanding for us humans,"
Andrej Karpathy said "I think it's doing some understanding in its weights, it understands, I think a lot about the world. And it has to in order to predict the next word in the sequence."
Lex Fridman said "So it's trained on the data from the internet. What do you think about this, this approach in terms of datasets of using data from the internet? Do you think the internet has enough structured data to teach AI about human civilization?"
Andrej Karpathy said "Yes, I think the internet has a huge amount of data. I'm not sure if it's a complete enough set. I don't know that text is enough for having a sufficiently powerful AGI as an outcome."
Lex Fridman said "Of course, there is audio and video and images and all that kind of stuff."
Andrej Karpathy said "Yeah. So text by itself, I'm a little bit suspicious about there's a ton of things we don't put in text and writing, just because they're obvious to us about how the world works and the physics of it and that things fall, we don't put that stuff in text, because why would you, we share that understanding. And so text is a communication medium between humans. And it's not a all encompassing medium with knowledge about the world. But as you pointed out, we do have video and we have images, and we've audio. And so I think that that definitely helps a lot. But we haven't trained models sufficiently across both across all of those modalities yet. So I think that's what a lot of people are interested in."
Lex Fridman said "But I wonder what that shared understanding of like, we might call common sense, has to be learned, Inferred in order to complete the sentence correctly. So maybe the fact that it's implied on the internet, the model is going to have to learn that, not by reading about it by inferring it in the representation. So like, common sense, just like we I don't think we learn common sense, like nobody says, tells us explicitly, we just figure it all out by interacting with the world, right? So here's a model of reading about the way people interact with the world and might have to infer that. I wonder, yeah, you you briefly worked on a project called the world of bits, training in our RL system to take actions on the internet, versus just consuming the internet, like we talked about, do you think there's a future for that kind of system interacting with the internet to help the learning?"
Andrej Karpathy said "Yes, I think that's probably the the final frontier for a lot of these models, because it's so as you mentioned, when I was at opening, I was working on this project called of bits. And basically, it was the idea of giving neural networks access to a keyboard and a mouse, and the idea of possibly"
Lex Fridman said "go wrong."
Andrej Karpathy said "So basically, you, you perceive the inputs of the screen pixels. And basically, the state of the computer is sort of visualized for human consumption in images of the web browser and stuff like that. And then you give the neural network the ability to press keyboards and use the mouse. And we're trying to get it to, for example, complete bookings, and, you know, interact with user interfaces. And"
Lex Fridman said "would you learn from that experience? Like, what was some fun stuff? This is super cool idea. Yeah. I mean, it's like, yeah, I mean, the step between observer to actor Yeah, is a super fascinating stuff."
Andrej Karpathy said "Well, it's the Universal Interface in the digital realm, I would say. And there's a Universal Interface in like the physical realm, which in my mind is a humanoid form factor kind of thing. We can later talk about Optimus and so on, but I feel like there's a they're kind of like, similar philosophy in some way, where the human the world, the physical world is designed for the human form. And the digital world is designed for the human form of seeing the screen and using keywords, not keyboard and mouse. So as the Minister of Universal Interface that can basically command the digital infrastructure we've built up for ourselves. And so it feels like a very powerful interface to to command and to build on top of now to your question as to like what I learned from that it's interesting, because the world of bits was basically too early, I think, at open AI at the time. This is around 2015 or so. And the zeitgeist at that time was very different in AI from the zeitgeist today. At the time, everyone was super excited about reinforcement learning from scratch. This is the time of the Atari paper, where neural networks were playing Atari Games, and beating humans in some cases, AlphaGo, and so on. So everyone's very excited about trading, training neural networks from scratch using reinforcement learning directly. It turns out that Reinforcement learning is extremely inefficient way of training neural networks, because you're taking all these actions and all these observations and you get some sparse rewards once in a while. So you do all this stuff based on all these inputs. And once in a while, you're like told you did a good thing. You did a bad thing. And it's just an extremely hard problem. You can't learn from that you You can burn the forest. And you can sort of brute force through it. And we saw that I think with, you know, with go and do it on so on and does work. But it's extremely inefficient, and not how you want to approach problems practically speaking. And so that's the approach that at the time, we also took the world of bits, we would have an agent, initialized randomly, so with keyboard, mash, and mouse mash, and tried to make a booking, and it's just like revealed the insanity of that approach very quickly, where you have to stumble by the correct booking in order to get a reward of you did it correctly, and you're never gonna stumble by it, by chance at random."
Lex Fridman said "So even with a simple web interface, there's too many options, there's just too many options."
Andrej Karpathy said "And it's too sparse of reward signal, and you're starting from scratch at the time. And so you don't know how to read, you don't understand pictures, images, buttons, you don't understand what it means to like, make a booking. But now what's happened is, it is time to revisit that and open your eyes interested in this. Companies like adapt, are interested in this and so on. And the idea is coming back, because the interface is very powerful. But now you're not training an agent from scratch, you are taking the GPT as initialization. So GPT is pre trained on all of text. And it understands what's a booking, it understands what's a submit, it understands quite a bit more. And so it already has those representations. They are very powerful. And that makes all the training significantly more efficient. And makes the problem tractable."
Lex Fridman said "Should the interaction be with like the way humans see it with the buttons and the language? Or should it be with HTML, JavaScript, and in the CSS, what's what do you think is the butter."
Andrej Karpathy said "So today, all this interaction is mostly on the level of HTML, CSS, and so on? That's done because of computational constraints. But I think ultimately, everything is designed for human visual consumption. And so at the end of the day, there's all the additional information is in the layout of the webpage, and what's next to you, and what's our red background, and all this kind of stuff, and not what it looks like visually. So I think that's the final frontier as we're taking in pixels, and we're giving out the keyboard mouse commands. But I think it's impractical still today,"
Lex Fridman said "do you worry about bots on the internet? Given given these ideas, given how exciting they are, I do worry about bots on Twitter being not the stupid boss that we see now with the crypto bots. But the bots that might be out there actually, we don't see that they're interacting in interesting ways. So this kind of system feels like it should be able to pass the I'm not a robot click button, whatever. We do actually understand how that test works. I don't quite like there's there's a there's a checkbox or whatever that you click is presumably tracking, like mouse movement, and the timing and so on. Yeah. So exactly this kind of system we're talking about should be able to pass that. So yeah, what do you feel about bots that are language models plus have some intractability and are able to tweet and reply and so on? Do you worry about that world?"
Andrej Karpathy said "Yeah, I think it's always been a bit of an arms race, between sort of the attack and the defense. So the attacker will get stronger, but the defense will get stronger as well. Our ability to detect that,"
Lex Fridman said "how do you defend? How do you detect? How do you know that your Karpaty account on Twitter is human? How would you approach it? Like if people were claiming, you know? How would you defend yourself? In the court of law that I'm a human? It's OCONUS. Yeah,"
Andrej Karpathy said "at some point, I think it might be, I think the society, society will evolve a little bit like we might start signing, digitally signing, some of our correspondents or, you know, things that we create. Right now, it's not necessary, but maybe in the future it might be, I do think that we are going towards a world where we share, we share the digital space with AI's synthetic beings. Yeah. And they will get much better, and they will share our digital realm, and they'll eventually share our physical realm as well. It's much harder. But that's kind of like the world we're going towards. And most of them will be benign and awful. And some of them will be malicious. And it's going to be an arms race trying to detect them."
Lex Fridman said "So I mean, the worst isn't the AI is the worst is the AI is pretending to be human. So I don't know if it's always malicious. There's obviously a lot of malicious applications. But yeah, it could also be, you know, if I was an AI, I would try very hard to pretend to be human because we're in a human world. Yeah, I wouldn't get any respect as an AI. Yeah, I want to get some love and respect. I don't think"
Andrej Karpathy said "intractable people are thinking about the proof of personhood. Yes. And we might start digitally signing our stuff. And we might all end up having like, basically some some solution for proof of personhood. It doesn't seem to me and tractable. It's just something that we haven't had to do until now. But I think once the need like really starts to emerge, which is soon, I think when people think about it much more."
Lex Fridman said "So but that too will be a race because obviously you can probably spoof or fake the proof of personhood. It seems to try to figure out how to probably. I mean, it's weird that we have like social security numbers and like passports and stuff. It seems like it's harder to fake stuff in the physical space. In the digital space, it just feels like it's gonna be very tricky. Very tricky to out. Because it seems to be pretty low cost to fake stuff. What are you gonna put an AI in jail? For, like trying to use a fake fake personhood proof? Yeah, I mean, okay, fine, you put a lot of guys in jail. But there'll be more as arbitrary, like exponentially more, the cost of creating bot is very low. Unless there's some kind of way to track accurately. Like, you're not allowed to create any program without showing, tying yourself to that program. Like you any program that runs on the internet, you'll be able to trace every single human programming that was involved with that product."
Andrej Karpathy said "And maybe you have to start declaring when, you know, we have to start drawing those boundaries and keeping track of okay, what are digital entities versus human entities? And what are the ownership of human entities and digital entities and something like that? I don't know. But I think I'm optimistic that this is this is possible. And at some, in some sense, we're currently in like the worst time of it, because all these bots suddenly have become very capable. But we don't have the fences yet built up as a society. And but I think that doesn't seem to me intractable it just something that we have to deal with."
Lex Fridman said "It seems weird that the twitter bot, like really crappy Twitter bots, are so numerous, I guess, is it. So I presume that the engineers at Twitter are very good. So it seems like what I would infer from that is, it seems like a hard problem, it they're probably catching, if I were to sort of steal man the case. It's a hard problem. And there's a huge cost to false positive, to, to removing a post by somebody, that's not a bot. That's creates a very bad user experience. So they're very cautious about removing the maybes. And maybe the bots are really good at learning what gets removed and not such that they can stay ahead of the removal process very quickly."
Andrej Karpathy said "My impression of it honestly, is there's a lot of low hanging fruit. I mean, just that's what I it's not my impression, it's not"
Lex Fridman said "what you have. Yeah, that's my impression as well. But it feels like maybe you're seeing the the tip of the iceberg. Maybe the number of bots is in like the trillions. And you have to like, just it's a constant assault of bots. And you Yeah, I don't know. You have to assume in that case, because the bots I'm seeing are pretty, like obvious, I can write a few lines of code that catch these bots."
Andrej Karpathy said "I mean, definitely, there's a lot of low hanging fruit. But I will say I agree that if you are a sophisticated actor, you could probably create a pretty good bar right now. You know, using tools like GPS, because it's a language model, you can generate faces that look quite good now. And you can do this at scale. And so I think it's quite possible, it's going to be hard to defend."
Lex Fridman said "There was a Google engineer that claimed that the lambda was essential. Do you think there's any inkling of truth to what he felt? And more importantly, to me, at least, do you think language models will achieve sentience or the illusion of sentience? soonish?"
Andrej Karpathy said "Ish? Yeah, to me, it's a little bit of a canary in the coal mine kind of moment, honestly, a little bit, because so this engineer spoke to like a chatbot at Google, and became convinced that this bot is sentient, asked us some existential philosophical question and gave like reasonable answers and looked real, and, and so on. So to me, it's a he was he was, he wasn't sufficiently trying to stress the system, I think and exposing the truth of it, as it is today. But I think this will be increasingly harder over time. So yeah, I think more and more people will basically become Yeah, I think more and more, there will be more people like that. Over time. As this gets better,"
Lex Fridman said "like forming emotional connection to an AI. It's perfectly plausible, in"
Andrej Karpathy said "my mind, I think these AIs are actually quite good at human human connection, human emotion, a ton of text on the internet is about humans and connection and love and so on. So I think they have a very good understanding in some, in some sense of, of how people speak to each other about this. And they're very capable of creating a lot of that kind of text. The there's a lot of like sci fi from 50s and 60s that imagined AI is in a very different way. They are calculating coal Vulcan like machines, that's not what we're getting today, we're getting pretty emotional AI, that actually are very competent and capable of generating, you know, plausible sounding text with respect to all of these topics. See, I'm"
Lex Fridman said "really hopeful about AI systems that are like companions that help you grow, develop as a human being, help you maximize long term happiness. But I'm also very worried about AI systems that figure out from the internet, that humans get attracted to drama. So these would just be like shit talking to you guys. That just constant Did you hear? Like, they'll do gossip? They'll do. They'll try to plant seeds of suspicion to other humans that you love and trust, and just kind of mess with people in you know, because because that's going to get a lot of attention to drama, maximize drama, on the path to maximizing engagement, and as humans will feed into that machine. Yeah. And get it'd be a giant drama shitstorm. So I'm worried about that. So is the objective function really defines the way that human civilization progresses with AI, isn't it? Yeah,"
Andrej Karpathy said "I think right now, at least today, they're not sort of, it's not correct to really think of them as goal seeking agents that want to do something, they have no long term memory or anything, they it's literally a good approximation of it is, you get 1000 words, and you're trying to predict the 1,001st. And then you continue feeding it in, and you are free to prompt it in whatever way you want. So in text, so you say, Okay, you are a psychologist, and you are very good, and you love humans. And here's a conversation between you and another human, human, Colin something, you something. And then it just continues the pattern. And suddenly, you're having a conversation with a fake psychologist who's like trying to help you. And so it's still kind of like an aroma of a tool is a people can prompt it an arbitrary waste, and it can create really incredible text. But it doesn't have long term goals over long periods of time, it doesn't try to sort of doesn't look that way right now."
Lex Fridman said "But you can do short term goals that have long term effects. So if my prompting, short term goal is to get onto a capacitor respond to me on Twitter, when I like, I think AI might that's the goal, but you might figure out the talking shit to you, it would be the best in a highly sophisticated, interesting way. And then you build up a relationship when you respond once and then it like, over time, it gets to not be sophisticated and just like, just talk shit. Okay, maybe you won't get to Andre, but it might get to another celebrity and might get into other big accounts. And then it'll just so with just that simple goal. Get them to respond. Yeah, maximize the probability of actual response. Yeah, I"
Andrej Karpathy said "mean, you could prompt a powerful model like this with their its opinion about how to do any possible thing you interested in it. So they will just they're kind of on track to become these Oracle's I could sort of think of it that way. They are. Oracle's currently is just text, but they will have calculators, they will have access to Google search, they will have all kinds of gadgets and gizmos, they will be able to operate the internet and find different information. And yeah, in some sense, that's kind of like currently what it looks like in terms of the development, do you think it'll"
Lex Fridman said "be an improvement eventually over what Google is for access to human knowledge, like, it'll be a more effective search engine to access human knowledge."
Andrej Karpathy said "I think there's definite scope and building a better search engine today. And I think Google, they have all the tools, all the people, they have everything, they need all the puzzle pieces, they have people training transformers, at scale, they have all the data. It's just not obviously they are capable as an organization to innovate on their search engine right now. And if they don't, someone else will, there's absolute scope for building a significantly better search engine built on these tools"
Lex Fridman said "is so interesting, a large company, where the search, there's already an infrastructure, it works as brings out a lot of money. So where structurally inside a company is their motivation to pivot. Yeah, to say, we're going to build a new search engine. Yep. That's hard. It's usually going to come from a startup, right?"
Andrej Karpathy said "That's, that would be Yeah, or some other common more competent organization. So currently, for example, maybe being has another shot at it, you know, as an"
Lex Fridman said "NGO, Microsoft ventures were talking offline."
Andrej Karpathy said "I mean, it definitely is really interesting, because search engines used to be about, okay, here's some query, here's, here's, here's web pages that look like the stuff that you have. But you could just directly go to answer and then have supporting evidence. And these, these models, basically, they've read all the texts and they've read all the web pages. And so sometimes when you see yourself going over to search results and sort of getting like a sense of like the average answer to whatever you're interested in, like that just directly comes out. You don't have to do that work. So they're kind of like Yeah, I think they have a way to this of distilling all that knowledge into, like some level of insight basically,"
Lex Fridman said "do you think of prompting as a kind of teaching and learning? Like this whole process? Like another layer? You know, because maybe that's what humans are already have that background model and then your, the world is prompting you."
Andrej Karpathy said "Yeah, exactly. I think the way we are programming these computers now, like GPS is converging to how you program humans. I mean, how do I program humans via prompt, I go to people and I prompt them to do things, I prompt them from information. And so natural language prompt is how we program humans. And we're starting to program computers directly in that interface. It's like pretty remarkable, honestly."
Lex Fridman said "So you've spoken a lot about the idea of software 2.0. All good ideas, become like cliches so quickly, like the terms it's kind of hilarious. It's like, I think Eminem once said that, like, if he gets annoyed by song he's written very quickly, that means it's going to be a big hit, because it's too catchy. But can you describe this idea and how you're thinking about it has evolved over the months and years? Since? Since you coined it?"
Andrej Karpathy said "Yeah. Yes, I had a blog post on software 2.0, I think several years ago now. And the reason I wrote that post is because I kept, I kind of saw something remarkable happening in like software development, and how a lot of code was being transitioned to be written not in sort of like C++ and so on. But it's written in the weights of a neural net, basically just saying that neural nets are taking over software, they're almost software and taking more more and more tasks. And at the time, I think not many people understood this, deeply enough that this is a big deal. It's a big transition. Neural networks were seen as one of multiple classification algorithms you might use for your data set problem on Kaggle. Like, this is not that this is a change in how we program computers. And I saw neural nets as this is going to takeover, the way we program computers is going to change, it's not going to be people writing a software in C++ or something like that, and directly programming the software, it's going to be accumulating training sets and datasets, and crafting these objectives by which we train these neural nets. And at some point, there's going to be a compilation process from the datasets and the objective and the architecture specification into the binary, which is really just the neural net weights and the forward pass of the neural net. And then you can deploy that binary. So I was talking about that sort of transition. And that's what the post is about. And I saw this sort of play out in a lot of fields. You know, autopilot, autopilot being one of them, but also just simple image classification, people thought, originally, you know, in the 80s, and so on that they would write the algorithm for detecting a dog and an image. And they had all these ideas about how the brain does it. And first we did tech corners, and then we detect lines, and then we stitch them up. And they were like really going at it, they were like thinking about how they're going to write the algorithm. And this is not the way you build it. And there was a smooth transition where, okay, first, we thought we were going to build everything, then we were building the features. So like Hawk features, and things like that, that detect these little statistical patterns from image patches. And then there was a little bit of learning on top of it, like a support vector machine, or binary classifier for cat versus dog and images on top of the features. So we wrote the features, but we trained the last layer as sort of the the classifier, and then people are like, actually, let's not even design the features, because we can't, honestly, we're not very good at it. So let's also learn the features. And then you end up with basically a convolutional neural net, where you're learning most of it, you're just specifying the architecture. And the architecture has tons of fill in the blanks, which has all the knobs, and you let the optimization write most of it. And so this transition is happening across the industry everywhere. And suddenly, we end up with a ton of code that is written in neural net weights. And I was just pointing out that the analogy is actually pretty strong. And we have a lot of developer environments for software 1.0, like we have IDE is how you work with code, how you debug code, how do you how you run code, how do you maintain code, we have GitHub. So I was trying to make those analogies in the new realm. Like what is the GitHub or software? It turns out that something that looks like hugging face right now? You know, and so I think some people took it seriously and build cool companies, and many people originally attacked the post. It actually was not well received when I wrote it. And I think maybe it has something to do with the title. But the post was not well received. And I think more people sort of have been coming around to it over time."
Lex Fridman said "Yeah. So you were the director of AI at Tesla, where I think this idea was really implemented at scale, which is how you have engineering teams doing software 2.0. So can you sort of linger on that idea of? I think we're in the really early stages of everything you just said, which is like GitHub, I IDs? Like how do we build engineering teams that, that work in software 2.0 system and the data collection and the data annotation? Which is all part of that software? 2.0? Like, what do you think? Is the task of programming software? 2.0? Is it debugging in the space of hyperparameters? Or is it also the bug in the space of data?"
Andrej Karpathy said "Yeah, the way by which you program the computer and influence its algorithm is not by writing the commands yourself, you're changing mostly the dataset, you're changing the loss functions of like, what the neural net is trying to do, how it's trying to predict things, but they're basically the assets and the architecture of the neural net. And so in the case of the autopilot, a lot of the datasets have to do with, for example, detection of objects, and lane line markings, and traffic lights, and so on. So you accumulate Massive Datasets of, here's an example. Here's the desired label. And then, here's roughly how the architecture, here's roughly what the algorithm should look like. And that's accomplished on neural net. So the specification of the architecture is like a hint as to what the algorithm should roughly look like. And then the fill in the blanks process of optimization is the training process. And then you take your neural net that was trained, it gets all the right answers on your data set, and you deploy it."
Lex Fridman said "So there's, in that case, perhaps in all, machine learning cases, there's a lot of tasks. So is coming up formulating a task, like for a multi 100 neural network is formulating a task part of the programming. Yeah, very much. So how you break down a problem into a set of tasks? Yeah,"
Andrej Karpathy said "I'm gonna high level, I would say, if you look at the software running in the autopilot, I gave a number of talks on this topic, I would say originally, a lot of it was written in software, 1.0, there's imagine lots of C++, right? And then gradually, there was a tiny neural net that was, for example, predicting, given a single image, is there like a traffic light or not? Or is there a lane line marking or not. And this neural net didn't have too much to do in this in the scope of the software, it was making tiny predictions on individual little image, and then the rest of the system stitched it up. So okay, we're actually we don't have just a single camera with eight cameras, we actually have eight cameras over time. So what do you do with these predictions? How do you put them together? How do you do the fusion of all that information? And how do you act on it, all of that was written by humans in C++. And then we decided, okay, we don't actually want to do all of that fusion in C++ code, because we're actually not good enough to write that algorithm, we want the neural nets to write the algorithm. And we want to port all that software into the two panels stack. And so then we actually had neural nets that now take all the eight camera images simultaneously and make predictions for all of that, also. And, actually, they don't make predictions in the in the space of images, they now make predictions directly in 3d. And actually, they don't, in three dimensions around the car. And now actually, we don't manually fuse the predictions over in 3d Over time, we don't trust ourselves to write that tracker. So actually, we give the neural net the information over time. So it takes these videos now, and makes us predictions. And so we're starting just like putting more and more power to the neural network processing. And at the end of it, the eventual sort of goal is to have most of the software potentially be enough to Panola. And because it works significantly better, humans are just not very good at writing software, basically."
Lex Fridman said "So the prediction is happening in this, like four D Land was three dimensional world over time. How do you do annotation in that world? What have you. So data annotation, whether it's self supervised, or manual, by humans, is, is a big part of this ultra 2.0? World?"
Andrej Karpathy said "Right? I would say by far in the industry, if you're like talking about the industry, and how, what is the technology of what we have available, everything is supervised learning. So you need a datasets of input desired output, and you need lots of it. And there are three properties of it that you need, you need it to be very large, you need it to be accurate, no mistakes, and you needed to be diverse, you don't want to just have a lot of correct examples of one thing, you need to really cover the space of possibility as much as you can. And the more you can cover the space of possible inputs, the better the algorithm will work at the end. Now, once you have really good datasets that you're collecting, curating, and cleaning, you can train your neural net on top of that, so a lot of the work goes into clean those datasets. Now, as you pointed out, it's probably it could be the question is how do you achieve a tariff. If you want to basically predict in 3d you need data in 3d to back that up. So in this video, we have eight videos coming from all the cameras of the system. And this is what they saw. And this is the truth of what actually was round. There was this card there was this car this car. These are lane line markings. This is geometry. The road, there's traffic light in this three dimensional position, you need the ground truth. And so the big question that team was solving, of course is how do you how do you arrive at that ground truth, because once you have a million of it, and it's large, clean and diverse than training a neural net on it works extremely well. And you can ship that into the car. And so there's many mechanisms by which we collected that train data, you can always go for human annotation, you can go for simulation as a source of ground truth, you can also go for what we call the offline tracker, that we spoken about at the AI day, and so on, which is basically an automatic reconstruction process for taking those videos and recovering the three dimensional sort of reality of what was around that car. So basically, think of doing like a three dimensional reconstruction as an offline thing. And then understanding that, okay, there's 10 seconds of video, this is what we saw. And therefore, here's a willing last cars and so on. And then once you have that annotation, you can train a neural net to imitate it."
Lex Fridman said "And how difficult to reconstruct the 3d reconstruction is difficult. But it can be done. So there's the there's overlap between the cameras, and you do the reconstruction. And there's perhaps there's any inaccuracy. So that's called an annotation step."
Andrej Karpathy said "Oh, yes, the nice thing about the annotation is that it is fully offline, you have infinite time, you have a chunk of one minute, and you're trying to just offline in a supercomputer somewhere, figure out where were the positions of all the cars, all the people, and you have your full one minute video from all the angles, and you can run all the neural nets you want. And they can be very efficient, massive neural nets. That can be neural nets that can't even run in the car later at test time. So they can be even more powerful neural nets than what you can eventually deploy. So you can do anything you want three dimensional reconstruction, neural nets, anything you want just to recover that truth. And then you supervise that truth."
Lex Fridman said "What have you learned? You said, No mistakes about humans doing annotation? Because I assume humans are. There's like a range of things that are good at in terms of clicking stuff on screen. Isn't that? How interesting is that you have a problem of designing an annotator where humans are accurate, enjoy it, like what are the even the metrics are efficient or productive? All that kind of stuff?"
Andrej Karpathy said "Yeah, so I grew the annotation team at Tesla from Bisca, zero to 1000. While I was there, that was really interesting, in my background, as a PhD student researcher, so growing that company organization was pretty crazy. But yeah, I think it's extremely interesting and part of the design process very much behind the autopilot as to where you use humans, humans are very good at certain kinds of annotations. They're very good, for example, a two dimensional annotations of images, they're not good at annotating cars over time and three dimensional space very, very hard. And so that's why we were very careful to design the tasks that are easy to do for humans, versus things that should be left to the off on tracker, like maybe the maybe the computer will do all the triangulation and 3d reconstruction. But the human will say exactly these pixels of the image are car. exactly these pixels are human. And so co designing the data annotation pipeline was very much bread and butter was what I was doing daily,"
Lex Fridman said "do you think there's still a lot of open problems in that space? Just in general annotation, where the stuff the machines are good at machines do and the humans do what they're good at. And there's maybe some iterative process,"
Andrej Karpathy said "right? I think, to a very large extent, we went through a number of iterations. And we learned a ton about how to create these datasets. I'm not seeing big open problems. Like originally, when I joined, I was like, I was really not sure how this will turn out here. But by the time I left, I was much more secure. And actually, we sort of understand the philosophy of how to create these datasets. And I was pretty comfortable with where that was at the time."
Lex Fridman said "So what are strengths and limitations of cameras for the driving task and your understanding, when you formulate the driving task as a vision task with eight cameras, you've seen that the entire you know, most of the history of the computer vision field when it has to do with neural networks. What just if you step back, what are the strengths and limitations of pixels of using pixels to drive?"
Andrej Karpathy said "Yeah, pixels, I think are a beautiful sensory, beautiful sensor, I would say things like cameras are very, very cheap. And they provide a ton of information ton of bits. Also, it's a extremely cheap sensor for a ton of bits. And each one of these bits as a constraint on the state of the world. And so you get lots of megapixel images, very cheap. And it just gives you all these constraints for understanding what's actually out there in the world. So vision is probably the highest bandwidth sensor. It's a very high bandwidth sensor. And"
Lex Fridman said "I love it. I love the pixels is is a constraint on the world, as is highly complex, high bandwidth constraint on the war on the state of the world."
Andrej Karpathy said "It's not just that but again, this real real importance of it's the sensor that humans use. Therefore everything is designed for that sensor attacks, the writing the flashing signs, everything is designed for vision. And so if you just find it everywhere, and so that's why that is the interface, you want to be in talking again about these universal interfaces. And that's where we actually want to measure the world as well, and then develop software for that sensor."
Lex Fridman said "But there's other constraints on the state of the world that humans use to understand the world. I mean, vision, ultimately, is the main one. But we're like, we're like, referencing our understanding of human behavior and some common sense, physics, that could be inferred from vision from, from a perception perspective, but it feels like we're using some kind of reasoning to predict the world."
Andrej Karpathy said "Yeah, and not just the pixels, I mean, you have a powerful prior, so right, for how the world evolves over time, etc. So it's not just about the likelihood term, coming up from the data itself, telling you about what you are observing, but also the prior term of like, where are the likely things to see and how do they likely move and so on?"
Lex Fridman said "And the question is, how complex is the the the range of possibilities that might happen in the driving task? Right, there still, is that you still an open problem of how difficult is driving, like, philosophically speaking? Do you work on driving? Do you understand how hard driving is?"
Andrej Karpathy said "Yeah, driving is really hard. Because it has to do with the predictions of all these other agents and the theory of mind, and you know, what they're gonna do? And are they looking at you? Are they where are they looking? Where are they thinking? Yeah, there's a lot that goes there, at the full tail off, you know, the, the expansion of the knowledge that we have to be comfortable with it eventually, the final problems are of that form. I don't think those are the problems that are very common. I think, eventually, they're important, but it's like really, in the tail end,"
Lex Fridman said "in the tail end, the rare edge cases. From the vision perspective, what are the toughest parts of the vision problem of driving?"
Andrej Karpathy said "Well, basically, the sensor is extremely powerful, but you still need to process that information. And so going from brightnesses of these pixel values to Hey, here, the three dimensional world is extremely hard. And that's what the neural networks are fundamentally doing. And so the difficulty really is in just doing an extremely good job of engineering the entire pipeline, the entire data engine, having the capacity to train these neural nets, having the ability to evaluate the system, and iterate on it. So I would say just doing this in production at scale is like the hard part. It's an execution problem. So the data"
Lex Fridman said "engineering, but also the the sort of deployment of the system such that has low latency performance, so as to do all the steps"
Andrej Karpathy said "for the neural net, specifically, just making sure everything fits into the chip on the car. And you have a finite budget of flops that you can perform, and, and memory bandwidth and other constraints. And you have to make sure it applies. And you can squeeze in as much compute as you can into the tiny"
Lex Fridman said "What have you learned from that process? Because it may be that's one of the bigger like, new things coming from a research background, where there's there's a system that has to run under heavily constrained resources has to run really fast. What What kind of insights have you learned from that? Yeah,"
Andrej Karpathy said "I'm not sure if it's if there's too many insights, you're trying to create a neural nets that will fit in what you have available. And you're always trying to optimize it. And we talked a lot about it on the AI day, and basically, the the triple backflips, that the team is doing, to make sure it all fits and utilizes the engine. So I think it's extremely good engineering. And then there's all kinds of little insights peppered in on how to do it properly."
Lex Fridman said "Let's actually zoom out because I don't think we talked about the data engine, the entirety of the layout of this idea that I think it's just beautiful with humans in the loop. Can you describe the data engine?"
Andrej Karpathy said "Yeah, the data engine is what I call the almost biological feeling like process by which you have perfect the training sets for these neural networks. So because most of the programming now is in the level of these datasets, and make sure they're large, diverse and clean, basically, you have a data set that you think is good, you train your neural net, you deploy it, and then you observe how well it's performing. And you're trying to always increase the quality of your dataset. So you're trying to catch scenarios, basically, that are basically rare. And it is in these scenarios that neural nets will typically struggling because they weren't told what to do in those rare cases in the dataset. But now you can close the loop because if you can now collect all those at scale, you can then feed them back into the reconstruction process I described and reconstruct the truth in those cases and add it to the dataset. So the whole thing ends up being like a staircase of improvement of perfecting your training set. And you have to go through deployments so that you can mine the parts that are not the It represented well in the data set. So your data set is basically imperfect, it needs to be diverse, it has pockets that are missing, and you need to pad out the pockets, you can sort of think of it that way. In the data,"
Lex Fridman said "what role do humans play in this? So what's the this biological system? Like? A human body is made up of cells? What role? Like how you optimize the human system, the multiple engineers collaborating, figuring out? What to focus on? What to contribute? Which, which task to optimize in this neural network? Who's in charge of figuring out which task needs more data? What can you do? Can you speak to the hyper parameters, the human system,"
Andrej Karpathy said "it really just comes down to extremely good execution from an engineering team who knows what they're doing. They understand intuitively, the physical philosophical insights underlying the data engine and the process by which the system improves, and how to again, like delegate the strategy of the data collection, and how that works. And then just making sure it's all extremely well executed. And that's where most of the work is not even the philosophizing or the research or the ideas of it is just extremely good execution is so hard when you're dealing with data at that scale."
Lex Fridman said "So your role in the data engine executing well on it is difficult and extremely important. Is there a priority of like, like a vision board of saying, like, we really need to get better at stoplights. Like the prioritization of tasks is essentially, in that comes from the data"
Andrej Karpathy said "that comes to the larger extents to what we are trying to achieve in the product roadmap, or we're trying to the release, we're trying to get out in the feedback from the QA team, or where the system is struggling or not the things we're trying to"
Lex Fridman said "improve. And the QA team gives some signal, some information in aggregate about the performance of the system and various conditions."
Andrej Karpathy said "And then of course, all of us drive it, and we can also see it, it's really nice to work with a system that you can also experience yourself. And you know, it drives you home, it's"
Lex Fridman said "Is there some insight you can draw from your individual experience that you just can't quite get from an aggregate statistical analysis of data? Yeah, it's so weird, right? Yes. It's, it's not scientific, in a sense, because you're just one anecdotal sample?"
Andrej Karpathy said "Yeah, I think there's a ton of it's a source of truth, it's your interaction with the system. And you can see it, you can play with it, you can perturb it, you can get a sense of it, you have an intuition for it. I think numbers just like have a way of numbers and plots and graphs are much harder. It hides a lot of"
Lex Fridman said "it's like, if you train in language model, it's really powerful way is by you interacting with it. Yeah. 100%, I try to build up an intuition."
Andrej Karpathy said "Yeah, I think like Elon also, like he always wanted to drive this the system himself, he drives a lot. And I want to say almost daily. So he also sees this as a source of truth, you driving the system, and it performing? And"
Lex Fridman said "what do you think? Tough questions here. So Tesla last year, removed radar from from the sensor suite, and now just announced that it's going to remove all ultrasonic sensors, relying solely on vision. So camera only? Does that make the perception problem harder or easier?"
Andrej Karpathy said "I would almost reframe the question in some way. So the thing is, basically, you would think that additional sensors,"
Lex Fridman said "by the way, can I just interrupt God, I wonder if language model ever do that? If you prompt it, let me rephrase your question. be epic. This is the wrong problem. Sorry,"
Andrej Karpathy said "like a little bit of a wrong question. Because basically, you would think that these sensors are an asset to you. Yeah. But if you fully consider the entire product in its entirety, the sensors are actually potentially a liability. Because the sensors aren't free, they don't just appear on your car, you need something you need have an entire supply chain, you have people procuring it, there can be problems with them, they may need replacement, they are part of the manufacturing process, they can hold back the line in production, you need to source them, you need to maintain them, you have to have teams that write the firmware, all of all of it. And then you also have to incorporate them fuse them into the system in some way. And so it actually like bloats, the, the a lot of it. And I think Elon is really good at Simplify, simplify best part is no part. And he always tries to throw away things that are not essential because he understands the entropy in organizations and an approach. And I think, in this case, the cost is high, and you're not potentially seeing it if you're just a computer vision engineer, and I'm just trying to improve my network. And is it more useful or less useful? How useful is it? And the thing is, if once you consider the full cost of a sensor, it actually is potentially a liability. And you need to be really sure that it's giving you extremely useful information. In this case, we looked at using it or not using it and the Delta was not massive, and so it's not useful."
Lex Fridman said "Is it"
Andrej Karpathy said "also bloat in the data engine like having more sense understand and is a distraction and the sensors you know, they can change over time. For example, you can have one type of say radar you can have Another type of radar that change over time, now suddenly you need to worry about it. Now suddenly you have a column in your SQLite telling you Oh, what sensor type was it, and they all have different distributions. And then they can just be contributed noise and entropy into everything. And they bloat stuff. And also, organizationally has been really fascinating to me that it can be very distracting. If you if, if you only want to get to work as vision, all the resources are on it, and you're building out a data engine. And you're actually making forward progress, because that is the the sensor with the most bandwidth, the most constraints on the world. And you're investing fully into that. And you can make that extremely good if you're using only a finite amount of sort of spend off focus across different facets of the system."
Lex Fridman said "And this kind of reminds me of rich Sutton's a better lesson. That just seems like simplifying the system in the long run. Now, of course, you know, know what the long route is, seems to be always the right solution. Yeah, yes, in that case was for URL, but it seems to apply generally, across all systems that do computation. Yeah. So where, what do you think about the LIDAR as a crutch debate? The battle between point clouds and pixels?"
Andrej Karpathy said "Yeah, I think this debate is always like, slightly confusing to me. Because it seems like the actual debate should be about like, do you have the fleet or not? That's like, the really important thing about whether you can achieve a really good functioning of an AI system at this scale?"
Lex Fridman said "So data collection systems? Yeah,"
Andrej Karpathy said "do you have a fleet or not, is significantly more important, whether you have LIDAR or not, it's just another sensor? And yeah, I think, similar to or the radar discussion, basically, I don't think it it basically doesn't offer extra extra information. It's extremely costly, it has all kinds of problems, you have to worry about it, you have to calibrate it, etc. It creates bloat and entropy, you have to be really sure that you need this, this sensor. In this case, I basically don't think you need it. And I think, honestly, I will make a stronger statement. I think the others, some of the other companies who are using it are probably going to drop it."
Lex Fridman said "Yeah. So you have to consider the sensor in the full in considering, can you build a big fleet that collects a lot of data? And can you integrate that sensor with that data and that sensor into a data engine that's able to quickly find different parts of the data that then continuously improves whatever the model that you're using?"
Andrej Karpathy said "Yeah, another way to look at it is like, vision is necessary in the sense that the drive, the world is designed for human visual consumption. So you need vision, it's necessary. And then also, it is sufficient, because it has all the information that you that you need for driving, and humans obviously has a vision to drive. So it's both necessary and sufficient. So you want to focus resources, and you have to be really sure if you're going to bring in other sensors, you could you could you could add sensors to infinity, at some point, you need to draw the line. And I think in this case, you have to really consider the full cost of any one sensor that you're adopting. And do you really need it? And I think the answer in this case is no."
Lex Fridman said "So what do you think about the idea that that the other companies are forming high resolution maps and constraining heavily the geographic regions in which they operate? Is that approach not in your, in your view, not going to scale over time to the entirety of the United States?"
Andrej Karpathy said "I think thing, as you mentioned, like they pre map all the environments, and they need to refresh the map, and they have a perfect centimeter level accuracy map of everywhere they're going to drive. It's crazy. How are you going to we've been talking about the economy actually changing the world, we're talking about the deployment, on a on a global scale of autonomous systems for transportation. And if you need to maintain a centimeter accurate map for Earth, or like for many cities and keep them updated, it's a huge dependency that you're taking on huge dependency. It's a massive, massive dependency. And now you need to ask yourself, do you really need it? And humans don't need it? Right. So it's, it's very useful to have a low level map of like, okay, the connectivity of your road, you know, that there's a fork coming up. When you drive an environment, you sort of have that high level understanding. It's like a small Google Map. And Tesla uses Google Map, like similar kind of resolution information in the system, but it will not pre map environments. So somebody sent me a lot of accuracy. It's a crutch, it's a distraction. It costs entropy. And it diffuses the team and dilutes the team, and you're not focusing on what's actually necessary, which is computer vision problem."
Lex Fridman said "What did you learn about machine learning, about engineering about life about yourself as one human being? From working with Elon Musk?"
Andrej Karpathy said "I think the most I've learned is about how to sort of run organizations efficiently and how to create efficient organizations and how to fight entropy in an organization."
Lex Fridman said "So human engineering in the fight against entropy. Yeah,"
Andrej Karpathy said "there's a there's a, I think Elon is a very efficient warrior, in the fight against entropy in organizations."
Lex Fridman said "What is the entropy in an organization look like? Exactly."
Andrej Karpathy said "It's process. It's It's process and in efficiencies and inefficiencies and that kind of stuff, yeah, meetings, he hates meetings. He keeps telling people to skip meetings if they're not useful. He basically runs the world's biggest startups. I would say, Tesla, SpaceX are the world's biggest startups. Tesla actually has multiple startups. I think it's better to look at it that way. And so I think he's, he's extremely good at at that. And, yeah, it's a very good intuition for streamlining processes, making everything efficient. Best part is no part simplifying, focusing. And just kind of removing barriers, moving very quickly, making big moves. All this is a very startup B, sort of seeming things, but at scale,"
Lex Fridman said "so strong drive to simplify from, from your perspective, I mean, that that also probably applies to just designing systems and machine learning. And otherwise, yeah, like, simplify, simplify, yes. What do you think is the secret to maintaining the startup culture in a company that grows? Is there can you introspect that?"
Andrej Karpathy said "I do think you need someone in a powerful position with a big hammer, like Elon, who's like the cheerleader for that idea, and ruthlessly, ruthlessly pursues it. If no one has a big enough hammer. Everything turns into committee's democracy within the company, process, talking to stakeholders decision making just everything just crumbles. If you have a big person who is also really smart, that has a big hammer, things move quickly."
Lex Fridman said "So you said your favorite scene Interstellar is the intense docking scene with the AI and Cooper talking saying, Cooper, what are you doing? Docking? It's not possible? No, it's necessary. Such a good line. By the way, just so many questions there. Why in the AI, in that scene, presumably is supposed to be able to compute a lot more than the human is saying it's not optimal. Why the human? I mean, that's a movie, but shouldn't they I know much better than the human. Anyway, what do you think is the value of setting seemingly impossible goals? So like? Our initial intuition, which seems like something that you have taken on, and Elon espouses that, where the initial intuition of the community might say, this is very difficult, and then you take it on anyway, with a crazy deadline? You just from a human engineering perspective? Have you seen the value of that?"
Andrej Karpathy said "I wouldn't say that setting impossible goals exactly is a good idea. But I think setting very ambitious goals is a good idea. I think there's a, what I call sublinear scaling of difficulty, which means that 10x problems are not 10x, hard, usually 10x 10x, harder problem is like two or 3x, harder to execute on. Because if you want to actually like if you want to improve a system by 10%, it costs some amount of work. And if you want to 10x improve the system, it doesn't cost, you know, 100x amount of the work. And it's because you fundamentally change the approach. And if you start with that constraint, that some approaches are obviously dumb and not going to work, and it forces you to reevaluate. And I think it's a very interesting way of approaching problem solving."
Lex Fridman said "It requires a weird kind of thinking, just going back to your like PhD days, is like, how do you think which ideas in the machine learning community are solvable? Yes, it's a it requires. What is that? I mean, there's the cliche of first principles thinking but like, it requires to basically ignore what the community is saying, because doesn't the community doesn't a community in science usually draw lines of what isn't as impossible, right? And like, it's very hard to break out of that without going crazy."
Andrej Karpathy said "Yep. I mean, I think a good example here is, you know, the deep learning revolution in some sense, because you could be in computer vision at that time, when, during the deep learning, sort of revolution of 2012, and so on. You could be improving a computer vision stack by 10%. Or it can just be saying, Actually, all this is useless. And how do I do 10x? Better computer vision? Well, it's not probably by tuning a hog feature detector, I need a different approach. I need something that is scalable, going back to Richard Sutton's. And understanding sort of like the philosophy of the bitter lesson, and then being like, actually, I need much more scalable system like a neural network that in principle works, and then having some deep believers that can actually execute on that mission and make it work. So that's the tech solution."
Lex Fridman said "What do you think is the timeline to solve the problem of autonomous driving? This still, in part, an open question?"
Andrej Karpathy said "Yeah, I think the tough thing with timelines of self driving, obviously, is that no one has created self driving. Yeah. So it's not like what do you think is the timeline to build this bridge? Well, we've built million bridges before. Here's how long that takes. It's, it's a no one has built autonomy. It's not obvious Some parts turned out to be much easier than others. So it's really hard to forecast you do your best based on trend lines and so on. And based on intuition, but that's why fundamentally, it's just really hard to forecast this. No one is even still"
Lex Fridman said "like being inside of it. It's hard to, to"
Andrej Karpathy said "Yes, some things turn out to be much harder, and some things turn out to be much easier. Do you"
Lex Fridman said "try to avoid making forecasts? Because like Elon doesn't avoid them, right? And has of car companies in the past have not avoided it? Either. Ford and other places have made predictions that we're going to solve level for driving by 2020 2021, whatever. And now, they all kind of backtrack on that prediction. I you as a as an AI person, do you find yourself privately make predictions? Or do they get in the way of like, your actual ability to think about a thing?"
Andrej Karpathy said "Yeah, I would say like, what's easy to say is that this problem is tractable. And that's an easy prediction to make. It's trying to, it's going to work. Yes, it's just really hard. Some things turn out to be harder than some things turn out to be easier. So but it's it definitely feels tractable. And it feels like, at least the team at Tesla, which is what I saw internally is definitely on track to that."
Lex Fridman said "How do you form a strong representation that allows you to make a prediction about tractability? So like, you're the leader of a lot, a lot of humans, you have to kind of say this is actually possible? Like, how do you build up that intuition doesn't have to be even driving. It could be other tasks, the who owns what difficult tasks that you work on your life, I mean, classification, achieving certain just an image net certain level of superhuman level performance."
Andrej Karpathy said "Yeah, expert intuition. Just intuition. That's belief."
Lex Fridman said "So just like thinking about it long enough, like studying, looking at sample data, like you said, driving, my intuition was really flawed on this, like, I don't have a good intuition about tractability. It could be either, it could be anything, it could be solvable, like, the driving task could be simplified into something quite trivial. Like, the solution to the problem would be quite trivial. And at scale, more and more cars driving perfectly, might make the problem much easier. Yes. And the more cars you have drive, like people learn how to drive correctly, not correctly, but in a way that's more optimal for heterogeneous system of autonomous and semi autonomous and manually driven cars, that could change stuff, then again, also, I've spent a ridiculous number of hours just staring at pedestrians crossing streets, thinking about humans, and it feels like the way we use eye contact, it sends really strong signals, and there's certain quirks and edge cases of behavior. And of course, a lot of the fatalities that happen have to do with drunk driving, and both on the pedestrian side and the driver side. So there's that problem of driving at night and all that kind of Yeah, so I wonder, you know, it's like the space of possible solution to autonomous driving includes so many human factor issues, that it's almost impossible to predict. It could be super clean, nice solutions."
Andrej Karpathy said "Yeah, I would say definitely like to use a game analogy, there's some fog of war. But you definitely also see the frontier of improvement. And you can measure historically what you've made progress. And I think, for example, least what I've seen, and probably five years at Tesla, when I joined, it barely kept lane, on the highway. I think going up from Palo Alto to SF was like three or four interventions, anytime the road would do anything geometrically or turn too much, it would just like not work. And so going from that to like a pretty competent system in five years, and seeing what happens is also under the hood, and what the scale at which the team is operating now with respect to data and compute, and everything else, is just a massive progress. So"
Lex Fridman said "you're climbing a mountain, and yes, fog, but you make a lot of progress, fog,"
Andrej Karpathy said "you're making progress, and you see what the next directions are. And you're looking at some of the remaining challenges and they're not like they're not perturbing you, and they're not changing your philosophy and you're not controlling, contorting yourself, you're like, actually, these are the things that we still need to do."
Lex Fridman said "The fundamental components of solving the problem seem to be there in the data engine to the computer, the computer on the car to the computer has a training, all that kind of stuff. So you've done over the years, you've been tested, you done a lot of amazing breakthrough ideas in engineering, all of it. From the data engine to the human side, all of it. Can you speak to why you chose to leave"
Andrej Karpathy said "Tesla, basically, as I described that run, I think over time, during those five years, I've kind of gotten myself into a bit of a managerial position. Most of my days were, you know, meetings and growing the organization and making decisions about sort of high level strategic decisions about it. The team in what it should be working on and so on. And it's kind of like a corporate executive role. And I can do it, I think I'm okay at it. But it's not like fundamentally what I, what I enjoy. And so I think, when I joined, there was no computer vision team, because Tesla was just going from the transition of using Mobileye, a third party vendor for all of its computer vision to having to build its computer vision system. So when I showed up, there were two people training deep neural networks. And they were training them at a computer at their, at their legs, like, that's"
Lex Fridman said "a basic classification task."
Andrej Karpathy said "Yeah. And so I kind of like grew that into what I think has a fairly respectable, deep learning team, a massive compute cluster, a very good data annotation organization. And I was very happy with where that was, it became quite autonomous. And so I kind of stepped away. And I, you know, I'm very excited to do much more technical things again. Yeah. And kind of like we focus on AGI"
Lex Fridman said "what was this soul searching? Like? He took a little time off? Like, what? How many mushrooms did you take? What what was going through your mind that human lifetime is finite? Yeah, he did a few incredible things. You're, you're one of the best teachers of AI in the world, you're one of the best. And I don't mean that I mean, in the best possible way, you one of the best tinkerers in the AI world. Meaning like, understanding the fundamental fundamentals of how something works by building it from scratch, and playing with it with a basic intuitions. It's like Einstein Fineman, we're all really good at this kind of stuff, like small example of a thing to, to play with it, to try to understand it. So that and obviously now with Tesla, you helped build a team of machine learning. Like engineers, and a system that actually accomplishes something in the real world. So given all that, like, what was the soul searching like?"
Andrej Karpathy said "What was hard? Because obviously, I love the company a lot. And I love I love Elon, I love Tesla, I want so it's hard to leave. I love the team, basically. About you, I think, actually, I will be potentially, like interested in revisiting it, maybe coming back at some point, are working on Optimus or kind of AGI at Tesla. I think Tesla is going to do incredible things. It's basically like it's a massive, large scale robotics kind of company with a ton of in house talent for doing really incredible things. And I think humanoid robots are going to be amazing. I think autonomous transportation is going to be amazing. All this happening at Tesla. So I think it's just a really amazing organization. So being part of it and helping it along, I think was very, it's gonna enjoy that a lot. Yeah, it was basically difficult for those reasons, because I love the company. But you know, I'm happy to potentially at some point, come back for act two. But I felt like at this stage, I built the team, it felt autonomous. And I became a manager. And I wanted to do a lot more technical stuff. I wanted to learn stuff. I want to teach stuff. And I just kind of felt like it was a good time for for a change of pace a little bit."
Lex Fridman said "What do you think is the best movie sequel of all times picking apart two? Because like, because most of them suck? What do you see what's movie sequels? A new tweet about movies. So just a tiny tangent is this once you've watched like a favorite movie sequel? Godfather Part Two. Are you saying the Godfather because you didn't even tweet or mentioned the godfather?"
Andrej Karpathy said "Yeah, I don't love that movie."
Lex Fridman said "I know. It hasn't been shouted that out. We're gonna edit out the hate towards the godfather. How dare you"
Andrej Karpathy said "make a strong statement? I don't know why. I don't know why, but I basically don't like any movie before. 1995. Something like that."
Lex Fridman said "Didn't you mentioned Terminator? Two. Okay, okay. That's"
Andrej Karpathy said "like a terminator two was a little bit later. 1990 No,"
Lex Fridman said "I think Terminator two was in a man like"
Andrej Karpathy said "Terminator one as well. So okay, so like few exceptions, but by and large, for some reason. I don't like movies before 1995 or something. They feel very slow. The camera is like zoomed out. It's boring. It's kind of naive. It's kind of weird. And also Terminator was very much ahead of its time. Yes. And the godfather. There's like no AGI. So"
Lex Fridman said "that's, I mean, but you have Goodwill Hunting was one of the movies you mentioned. And that doesn't have any AGI either. I guess that's mathematics. Yeah,"
Andrej Karpathy said "I guess occasionally. I do enjoy movies that don't feature or like Anchorman that has. That's the thinker, man. It's so good."
Lex Fridman said "I don't understand. Um, he's speaking of AGI because I don't understand why Will Ferrell is so funny. It doesn't make sense. It doesn't compute. There's just something about him. And he's a singular human because you don't get that many comedies these days and I wonder if it has to do about the culture or the like the the machine of Hollywood or does it have to do with just we got lucky with certain people in comedy. It came together because he is a single human. That was a ridiculous tangent. I apologize. But you mentioned humanoid robot. So what do you think about Optimus about About Do you think we'll have robots in the factory in the home in 1020 3040 50 years?"
Andrej Karpathy said "Yeah, I think it's very hard project, I think it's going to take a while. But who else is going to build humanoid robots at scale. And I think it is a very good form factor to go after. Because like I mentioned that the world is designed for humanoid form factor, these things will be able to upgrade our machines, they will be able to sit down in chairs, potentially even drive cars. Basically, the world is designed for humans, that's the fourth factor you want to invest into and make work overtime. I think, you know, there's another school of thought, which is, okay, pick a problem and design a robot to it. But actually designing a robot and getting a whole data engine and everything behind it to work is actually incredibly hard problem. So it makes sense to go after General interfaces that, okay, they are not perfect for any one given task. But they actually have the generality of just with a prompt with English able to do something across. So I think it makes a lot of sense to go after a general interface in the physical world. And I think it's a very difficult project is going to take time. But I see no other no other company that can execute on that vision, I think it's going to be amazing, like, basically physical labor. Like if you think transportation is large market, try physical labor."
Lex Fridman said "But it's not just physical labor. To me, the thing that's also exciting is social robotics. So the relationship will have on different levels with those robots. That's why I was really excited to see optimistic. People have criticized me for the excitement. But I've worked with a lot of research labs that do humanoid legged robots, Boston Dynamics unitary a lot, there's a lot of companies that do legged robots. But that's the the elegance of the movement is a tiny, tiny part of the big picture. So integrating the two big exciting things to me about Tessa doing humanoid or any legged robots, is clearly integrating into the data engine. So the data engine aspect, so the actual intelligence for the perception in the in the control and the planning and all that kind of stuff, integrating into this huge the fleet that you mentioned, right. And then speaking of fleet, the second thing is the mass manufacture is just knowing, cultural Li, driving towards a simple robot that's cheap to produce, at scale. Yeah. And doing that, well, having experienced to do that, well, that changes everything. That's why that's a very different culture, and style, the Boston Dynamics, who by the way does those robots are just the way they move, it's like, it'll be a very long time before Tesla can achieve the smoothness of movement. But that's not what it's about. It's about, it's about the entirety of the system, like we talked about the data engine and the fleet. That's super exciting, even the initial sort of models. But that too, was really surprising that in a few months, you can get prototype."
Andrej Karpathy said "Yep. And the reason that happened very quickly is, as you alluded to, there's a ton of copy paste from what's happening in the autopilot, a lot. The amount of expertise that like came out of the woodworks at Tesla for building the human robot was incredible to see. Like, basically Elon said, at one point, were doing this. And then next day, basically, like all these CAD models started to appear, and people talking about like the supply chain and manufacturing. And people showed up with like screwdrivers and everything like the other day, and starts, like put together the body. And I was like, Whoa, like all these people exist at Tesla. And fundamentally, building a car is actually not that different from building a robot, the same. And that is true, not just for the hardware pieces. And also, let's not forget hardware, not just for demo, but manufacturing, of that hardware at scale is a whole different thing. But for software as well. Basically, this robot currently thinks it's a car sort of have"
Lex Fridman said "a midlife crisis, at some, it thinks"
Andrej Karpathy said "it's a car. Some of the earlier demos actually we were talking about potentially doing them outside in the parking lot, because that's where all of the computer vision that was like working out of the box, instead of like inside. But all the operating system everything just copy pastes, computer vision, mostly copy paste, I mean, you have to retrain the neural nets, but the approach and everything and data engine and offline trackers and the way we go about the occupancy tracker, and so on everything copy paste, you just need to retrain the neural nets. And then the planning control, of course has to change quite a bit. But there's a ton of copy paste from what's happening at Tesla. And so if you were to if you were to go with goal of like, okay, let's build a million humanoid robots, and you're not Tesla. That's that's a lot to ask if you're a Tesla. It's actually like, it's not, it's not that crazy. And then"
Lex Fridman said "the follow up questions and how difficult just like we're driving, how difficult is the manipulation task, such that it can have an impact that scale? I think, depending on the context, the really nice thing about robotics is that unless you do manufacturing, that kind of stuff Is there is more room for error driving associated critical. And so the and also time critical, like a robot is allowed to move slower? Which is nice. Yes."
Andrej Karpathy said "I think it's going to take a long time. But the way you want to structure the development is you need to say, Okay, it's going to take a long time, how can I set up the product development roadmap, so they're making revenue along the way, I'm not setting myself up for a 01 loss function where it doesn't work until it works, you don't want to be in that position, you want to make it useful almost immediately. And then you want to slowly deploy it. And at scale and safely at scale, and you want to set up your data engine, your improvement loops, the telemetry, the evaluation, the harness and everything. And you want to improve the product over time incrementally and you're making revenue along the way, that's extremely important. Because otherwise, you cannot build these, these large undertakings just like don't make sense economically. And also, from the point of view of the team working on it, they need the dopamine along the way, they're not just going to make a promise about this being useful. This is going to change the world in 10 years, when it works. This is not where you want to be. You want to be in a place like I think our politics today where it's offering increased safety and, and convenience of driving today, people pay for it, people like it, people purchase it. And then you also have the greater mission that you're working towards."
Lex Fridman said "And you see that so the dopamine for the team, that that was a source of happiness,"
Andrej Karpathy said "yes. you're deploying this people like it, people drive it, people pay for it, they care about it. There's all these YouTube videos, your grandma drives it, she gives you feedback, people like it, people engage with it, you engage with it huge."
Lex Fridman said "Do people that drive Tesla's like recognize you and give you love? Like, like, Hey, thanks for them. For the nice feature that is doing?"
Andrej Karpathy said "Yeah, I think the tricky thing is like, some people really love you some people unfortunately, like you're working on something that you think is extremely valuable, useful, etc. Some people do hate you. There's a lot of people who like hate me and the team and whatever, the whole project. And I think Tesla drivers, many cases, they're"
Lex Fridman said "not actually yeah, that's that's actually makes me sad about humans, or the current. The ways that humans interact. I think that's actually fixable. I think humans want to be good to each other. I think Twitter and social media is part of the mechanism that actually somehow makes the negativity more viral. But it doesn't deserve like disproportionately add of like a viral viral boost negativity, but I wish people would just get excited about. So suppress some of the jealousy, some of the ego and just get excited for others. And then there's a Karma aspect to that you get excited for others, they'll get excited for you. Same thing in academia, if you're not careful, there's like a dynamical system there. If you if you think of in silos and get jealous of somebody else being successful, that actually, perhaps counter intuitively, least the less productivity of you as a community and you individually. I feel like if you keep celebrating others, that actually makes you more successful. Yeah. And I think people haven't in, depending on the industry haven't quite learned that yet."
Andrej Karpathy said "Yeah. Some people are also very negative and very vocal. So they're very prominently featured. But actually, there's a ton of people who are cheerleaders, but they're silent cheerleader, cheerleaders. And when you talk to people just in the world, they will tell you, it's amazing. It's great, especially like people who understand how difficult that is to get this stuff working, like people who have built products, makers, intrapreneur entrepreneurs, like make making this work and changing something is incredibly hard. Those people are more likely to clearly."
Lex Fridman said "Well, one of the things that makes me sad is some folks in the robotics community don't do the cheerleading, and they should. There's a because they know how difficult is well, they actually sometimes don't know how difficult it is to create a product that scale. Right? Yeah, they actually deploy in the real world. A lot of the development of robots and AI system is done on very specific small benchmarks as opposed to real world conditions."
Andrej Karpathy said "Yes. Yeah, I think it's really hard to work on robotics in academic setting,"
Lex Fridman said "or AI systems that apply in the real world you've criticized you flourished and loved for time, the ImageNet, the famed ImageNet dataset, and have recently had some words of criticism that the academic research ml community gives a little too much love still to the image net are like, those kinds of benchmarks. Can you speak to the strengths or weaknesses of datasets used in machine learning research?"
Andrej Karpathy said "Actually, I don't know that I recall the specific instance where I was unhappy or criticizing ImageNet I think ImageNet has been extremely valuable. It was basically a benchmark that allowed the deep learning community to demonstrate that deep neural networks actually work. It was a there's a massive value in that. So I think ImageNet was useful but um, basically it's become a bit of an M nest at this point. So M nest is like little to 28 by 28, grayscale digits. There's kind of a joke data set that everyone like just cry Just because no papers"
Lex Fridman said "written on them this though, right? Maybe they should have strong papers, like papers that focus on like, how do we learn with a small amount of data? That stuff?"
Andrej Karpathy said "Yeah, I could see that being helpful, but not in sort of like mainline computer vision research anymore. Of course,"
Lex Fridman said "I think the way I've heard you somewhere, maybe I'm just imagining things. But I think you said like, ImageNet was a huge contribution to the community for a long time. And now it's time to move past those kinds of,"
Andrej Karpathy said "well, ImageNet has been crushed. I mean, you know, the error rates are. Yeah, we're getting like 90% accuracy, in 1000, classification way, prediction, and I've seen those images. And it's like, really high. That's really, that's really good. If I recall correctly, the top five error rate is now like 1%, or something,"
Lex Fridman said "given your experience with a gigantic real world dataset? Would you like to see benchmarks move into certain directions that the research community uses?"
Andrej Karpathy said "Unfortunately, I don't think academics currently have the next ImageNet we've obviously I think we've crushed em NIST, we've basically kind of crushed ImageNet. And there's no next sort of big benchmark that the entire community rallies behind and uses. You know, for further development of these networks."
Lex Fridman said "I wonder what it takes for dataset to captivate the imagination of everybody, like where they all get behind it, that that could also need, like a viral like a leader? Right? Somebody with popularity? I mean, yeah, what image that take off? Is there? Or is it just the accident of history? It was"
Andrej Karpathy said "the right amount of difficult. It was the right amount of difficult and simple and interesting enough, it just kind of like it was it was the right time for that kind of a dataset."
Lex Fridman said "Question from Reddit? What are your thoughts on the role that synthetic data and game engines will play in the future of neural net model development?"
Andrej Karpathy said "I think as neural nets converge to humans, the value of simulation to neural nets will be similar to value of simulation to humans. So people use simulation for people use simulation because they can learn something in that kind of a system. And without having to actually experience it."
Lex Fridman said "But are you referring to the simulation would do in our head? Is no"
Andrej Karpathy said "no sorry, simulation? I mean, like video games or, you know, other forms of simulation for various professionals."
Lex Fridman said "So let me push back on that. Because that maybe there's simulation that we do in our heads, like, simulate if I do this, what do I think will happen? Okay, that's like internal simulation. Yeah, internal? Isn't that what we're doing? As humans before we act? Oh, yeah."
Andrej Karpathy said "But that's independent from like, the use of simulation in the sense of like computer games, or using simulation for training set creation? Or"
Lex Fridman said "is it independent? Or is it just loosely correlated, because like, it's not useful to do like, counterfactual, or like edge case simulation to like, you know, what happens if there's a nuclear war? What happens if there, you know, like, those kinds of things exist? Yeah,"
Andrej Karpathy said "that's a different simulation from like, Unreal Engine. That's how I interpreted the question. Ah, so"
Lex Fridman said "like, simulation of the average case? Is that what's Unreal Engine? What What? What do you mean by Unreal Engine? So simulating a world of physics to that world? Why is that different? Like, because you also can add behavior to that world. And you could try all kinds of stuff, right? You could throw all kinds of weird things into it. Unreal Engine is not just about simulate. I mean, I guess it is about being the physics of the world. It's also doing something with that."
Andrej Karpathy said "Yeah, the graphics, the physics and the agents that you put into the environment and stuff like that."
Lex Fridman said "See, I think you've I feel like you said that it's not that important, I guess, for the future of AI development. Is that Is that correct to interpret?"
Andrej Karpathy said "I think humans use simulators for humans use simulators, and they find them useful. And so computers will use simulators and find them useful."
Lex Fridman said "Okay, so you just saying it's not that I don't use simulators. Very often, I play a video game every once in a while, but I don't think I derive any wisdom about my own existence from from those video games. It's a momentary escape from reality versus a source of wisdom about reality. So I don't so I think that's a very polite way of saying simulation is not that useful."
Andrej Karpathy said "Yeah, maybe maybe not. I don't see it as like a fundamental, really important part of like training neural nets currently. But I think, as neural nets become more and more powerful, I think you will need fewer examples to train additional behaviors. And simulation is of course, there's a domain gap and a simulation that is not the real world is slightly something different. But with a powerful enough neural net, you need the domain gap can be bigger, I think because neural net people sort of understand that even though it's not the real world. It like has all this high level structure that I'm supposed to be like learn from"
Lex Fridman said "so then you don't that will actually yeah, we'll be able to leverage the synthetic data better. Yes, by close And then get back to understanding in which ways this is real data. Exactly. Ready to do better questions next time that was, that was a question was I'm just kidding. All right. So is it possible? Do you think speaking of feminist to construct neural nets and training processes that require very little data? So we've been talking about huge datasets like the internet for training. I mean, one way to say that is, like you said, like the queering itself as another level of training, I guess. And that requires a little data. Yeah. But do you see any value in doing research and kind of going down the direction of can we use very little data to train to construct the knowledge"
Andrej Karpathy said "base and 2%, I just think like, at some point, you need a massive data set. And then when you pre train your massive neural net and get something that you know, is like a GPT or something, then you're able to be very efficient at training, any arbitrary new task. So a lot of these GPS, you can do tasks like sentiment analysis, or translation or so on, just by being prompted with very few examples. Here's the kind of thing I want you to do. Like, here's an input sentence, here's the translation into German input sentence translation to German input, sentence blank, and the neurological complete the translation German, just by looking at sort of the example you've provided. So that's an example of a very few shot learning in the activations of the neural map instead of the weights of the neural net. And so I think, basically, just like humans, neural nets will become very data efficient at learning any other new tasks. But at some point, you need a massive data set to pre train your network."
Lex Fridman said "Together, probably we humans have something like that. Do we? Do we have something like that? Do we have a passive in the background, background model constructing thing that just runs all the time in the self supervised way? We're not conscious of it?"
Andrej Karpathy said "I think humans definitely. I mean, obviously, we have, we learned a lot during during our life span. But also, we have a ton of hardware that helps us initialize initialization, coming from sort of evolution. And so I think that's also a really big a big component. A lot of people in the field, I think they just talk about the amounts of like seconds and the, you know, that person has left pretending that this is a tabula rasa, sort of like a zero initialization of the neural net. And it's not like, you can look at a lot of animals, like for example, zebras, zebras get born, and they see and they can run, there's zero train data in their lifespan, they can just do that. So somehow, I have no idea how evolution has found a way to encode these algorithms. And these neural net initializations are extremely good into at CGS and have no idea how this works. But apparently, it's possible because here's a proof by existence."
Lex Fridman said "There's something magical about going from a single cell to organism that is born to the first few years of life. I kind of like the idea that the reason we don't remember anything about the first few years of our life, is that it's a really painful process. Like it's a very difficult challenging training process. Yeah, like, intellectually, like, and maybe, yeah, I mean, why don't we remember any of that, there might be some crazy training going on. And that the, maybe that's the background model of training that is, is very painful. And so it's best for the system, once it's trained not to remember how to structure"
Andrej Karpathy said "I think it's just like, the hardware for long term memory is just not fully developed. I kind of feel like the first few years of, of infancy is not actually like learning. It's brain maturing. Yeah. We're born premature. There's a theory along those lines because of the birth canal and the swelling of the brain. And so we're bumper mature, and then the first few years were just the brains maturing. And then there's some learning eventually. That's my current view on it."
Lex Fridman said "What do you think? Do you think neural nets can have long term memory? Like that approach is something like humans, do you think neural do you think needs to be another meta architecture on top of it to add something like a knowledge base that learns facts about the world and all that kind of stuff?"
Andrej Karpathy said "Yes, but I don't know to what extent it will be explicitly constructed. It might take unintuitive forms where you are telling the GPT like, Hey, you have a you have a declarative memory bank to which you can store and retrieve data from. And whenever you encounter some information that you find useful, just save it to your memory bank. And here's an example of something you have retrieved and here's how you say it. And here's how you load from it. You just say load, whatever, you teach it in text in English. And then it might learn to use a memory bank from from that. Oh, so"
Lex Fridman said "it says a neural net is the architecture for the background model the the base thing and then yeah, everything else is just on top of it."
Andrej Karpathy said "So it's not just the tax, right? It's a you're giving gadgets and gizmos. So you're teaching some kind of a special language by which it can it can save arbitrary information and retrieve it at a later time and you're You're telling me about these special tokens and how to arrange them to use these interfaces. It's like, Hey, you can use a calculator. Here's how you use it, just do five, three plus four, one equals, and when equals is there, a calculator will actually read out the answer, and you don't have to calculator yourself. And you just like, tell it in English, this might actually work."
Lex Fridman said "Do you think in that sense, God was interesting, the Deep Mind system that it's not just the language, but actually throws it all? In the same pile, images, actions, all that kind of stuff. That's basically what we're moving towards?"
Andrej Karpathy said "Yeah, I think so. So Gato is is very much hate Kitchen Sink off approach to like, reinforcement learning lots of different environments with a single fixed transformer model, right. I think it's a very sort of early result in that in that realm, but I think, yeah, it's along the lines of what I think things will eventually look like."
Lex Fridman said "Right? So this is the early days of a system that eventually will look like this, like from a Richard return perspective."
Andrej Karpathy said "Yeah, I'm not super huge fan of I think all these interfaces that like look very different. I would want everything to be normalized into the same API. So for example, screen pixels, versus API, instead of having like different world environments that have very different physics and joint configurations and appearances, and whatever, and you're having some kind of special tokens for different games that you can plug, I'd rather just normalize everything to a single interface. So it looks the same to the neural net, if that makes sense."
Lex Fridman said "So it's all going to be pixel based Pong in the end? I think so. Okay, let me ask you about your own personal life. A lot of people want to know you're one of the most productive and brilliant people in the history of AI. What is a productive day in the life of Andrej Karpathy look like? What time do you wake up you imagine some kind of difference between the average productive day and a perfect productive day. So the perfect productive day is the thing we strive towards. And the average is kind of what it kind of converges to given all the mistakes and raw human eventualities and so on. Yep. So what times you wake up, when you're a morning person,"
Andrej Karpathy said "I'm not a morning person, I'm a night owl, for sure. It's stable or not, it's semi stable, like a eight or nine or something like that. During my PhD, it was even later, I used to go to sleep usually at 3am. I think the am hours are, are precious, a very interesting time to work because everyone is asleep. At 8am, or 7am, the East Coast is awake. So there's already activity, there's already some text messages, wherever there's stuff happening, you can go on like some news website, and there's stuff happening distracting. At 3am, everything is totally quiet. And so you're not going to be bothered, and you have solid chunks of time to do your work. So I like those periods, Night Owl by default. And then I think like productive time, basically, what I like to do is you need a you need to like build some momentum on the problem without too much distraction. And you need to load your REM, your working memory with that problem. And then you need to be obsessed with it. When you're taking shower, when you're falling asleep. You need to be obsessed with the problem and it's fully in your memory, and you're ready to wake up and work on it right there."
Lex Fridman said "So that is the skill is this in a scale temporal skill of a single day or a couple of days a week, a month."
Andrej Karpathy said "So I can't talk about one day basically in isolation, because it's a whole process, when I want to get when I want to get productive in the problem, I feel like I need a span of a few days where I can really get in on that problem. And I don't want to be interrupted. And I'm going to just be completely obsessed with that problem. And that's where I do most of my good workouts."
Lex Fridman said "You've done a bunch of cool, like little projects in a very short amount of time very quickly. So that requires you just focusing on it."
Andrej Karpathy said "Yeah, basically, I need to load my working memory with the problem. And I need to be productive because there's always like a huge fixed cost to approaching the problem. You know, like I was struggling with this, for example, at Tesla because I want to work on like small side project. But okay, you first need to figure out okay, I need to SSH into my cluster, I need to bring up a VS code editor. So I can like work on this, I need to I run into some stupid error because of some reason, like you're not at a point where you can be just productive right away, you are facing barriers. And so it's about really removing all of that barrier and you're able to go into the problem and you have the full problem loaded in your memory"
Lex Fridman said "and somehow avoiding distractions of all different forms like news stories, emails, but also distractions from other interesting projects that you previously worked on are currently working on so on you just want to really focus your mind"
Andrej Karpathy said "and I mean I can take some time off for distractions and in between but I think it can be too much. You know most of your day is sort of like spent on that problem. And then you know, I drink coffee or you have my morning routine I look at some news, Twitter Hacker News, Wall Street Journal, etc. So he's great so basically you"
Lex Fridman said "wake up Have some coffee, are you trying to get to work as quickly as possible do you do taking this diet of of like what the hell's happening in the world first?"
Andrej Karpathy said "I am I do find it interesting to know about the world. I don't Know that it's useful or good, but it's part of my routine right now. So I do read through a bunch of news articles, and I want to be informed. And I'm suspicious of it. I'm suspicious of the practice. But currently, that's where I am. Oh, you mean"
Lex Fridman said "suspicious about the positive effect of that practice on your productivity and your well being and well being psychologically, and also on your ability to deeply understand the world? Because how there's a bunch of source of information, you're not really focused on deeply integrating that's a little bit distracting, you're in terms of perfectly productive day, for what how long of a stretch of time, in one session, do try to work and focus on the thing. A couple hours is a one hour is it? 30 minutes, 10 minutes,"
Andrej Karpathy said "I can probably go like a small few hours. And then I need some breaks in between, for like food and stuff. And yeah, but I think like, it's still really hard to accumulate hours, I was using a tracker that told me exactly how much time I spent coding any one day. And even on a very productive day, I still spent only like six or eight hours. Yeah. And it's just because there's so much padding, commute, talking to people, food, etc. There's like a cost of life, just living and sustaining and homeostasis. And just maintaining yourself as a human is very high."
Lex Fridman said "And that there seems to be a desire within the human mind to to, to participate in society that creates that pattern. Because I, the most productive days have ever had is just completely from start to finish his tuning out everything, and just isn't there. And then you could do more than six and eight hours. Yeah. Is there some wisdom about what gives you strength to do like, tough days of long focus?"
Andrej Karpathy said "Yeah, just like, whenever I get obsessed about a problem, something just needs to work. Something just needs to exist, it needs"
Lex Fridman said "to exist in unit. And so you're able to deal with bugs and programming issues and technical issues and design decisions that turn out to be the wrong ones, you're able to think through all that given given that you want to think to exist,"
Andrej Karpathy said "yeah, nice to exist. And then I think, to me, also, a big factor is, you know, our other humans are going to appreciate it, or they're going to like it. And that's a big part of my motivation. If I'm helping humans, and they seem happy. They say nice things. They tweet about it or whatever, that gives me pleasure, because I'm doing something useful."
Lex Fridman said "So like, you do see yourself sharing it with the world like Well, yes, on GitHub was a blog post or two videos."
Andrej Karpathy said "Yeah, I was thinking about it. Like, suppose I did all these things, but did not share them. I don't think I would have the same amount of motivation that I can build up."
Lex Fridman said "You enjoy the feeling of other people gaining value and happiness from the stuff that you've created. Yeah. What about diet is there I saw you played with intermittent fasting, you fast ZZ that help with everything, with the things you played was been most beneficial to the your ability to mentally focus on the thing, and just meant the mantra productivity and happiness is still fast. Yeah, so"
Andrej Karpathy said "fast. But I do intermittent fasting. But really what it means at the end of the day is I skipped breakfast. And yeah, so I do 18 Six, roughly, by default, when I'm in my steady state, if I'm traveling or doing something else, I will break the rules. But in my steady state, I do 18 Six. So I eat only from 12 to six. Not a hard rule, and I break it often. But that's my default. And then, yeah, I've done a bunch of random experiments. For the most part right now, where I've been for the last year and a half I want to say is plant based or plant forward? I heard plant forward, it sounds that I mean, exactly. I didn't actually know the differences, but it sounds better in my mind. But it just means I prefer plant based food, and raw or cooked or I prefer cooked and plant based."
Lex Fridman said "So plant based. Forgive me, I don't actually know how wide the category of plan entails."
Andrej Karpathy said "Well, it just means that you're not like lectured about is you can flex and you just prefer to eat plants. And you know, you're not making you're not trying to influence other people. And if someone is you come to someone's house party and they serve you a steak that they're really proud of you will eat it. Yes."
Lex Fridman said "Oh, that's beautiful. I mean, that's the flip side of that, but I'm very sort of flexible. Have you tried doing one meal a day?"
Andrej Karpathy said "I have. Accidentally, not consistently, but I've accidentally had that. I don't I don't like it. I think it makes me feel not good. It's too it's too much too much of a hit. Yeah. And so currently, I have about two meals a day. 12 and six."
Lex Fridman said "I do that nonstop. I'm doing you know, do one meal a day because it's interesting. It's interesting field. Have you ever fasted longer than a day?"
Andrej Karpathy said "Yeah, I've done a bunch of water fasts because I was curious what happens when anything interesting? Yeah, I would say so. I mean, you know, what's interesting is that you're hungry for two days, and then starting day three or so you're not hungry. You It's like such a weird feeling because you haven't eaten in a few days and you're not hungry."
Lex Fridman said "Isn't that weird? It's really one of the many weird things about human biology is figure something out and finds finds another source of energy or something like that. Or relaxes the system. I don't know how Yeah,"
Andrej Karpathy said "the body is like you're hungry, you're hungry, and then it just gives up it's like okay, I guess we're fasting now. There's nothing And then it just kind of like focuses on trying to make you not hungry, and not feel the damage of that and trying to give you some space to figure out the food situation."
Lex Fridman said "So I, you still to this day, most productive at night,"
Andrej Karpathy said "I would say I am, but it is really hard to maintain my PhD schedule. Especially when I was say, working at Tesla, and so on. It's a non starter. So But even now, like, you know, people want to meet for various events, they society lives in a certain period of time. And you sort of have to like, work with that."
Lex Fridman said "It's hard to like, do a social thing. And then after that return and do work,"
Andrej Karpathy said "yeah, it's just really hard."
Lex Fridman said "That's why I try to do social thing. I try not to do too, too much drinking so I can return and continue doing work. But a Tesla is there is there conversions, then Tesla, but any, any company? Is there a convergence tones the schedule? Or is there more? Is that how humans behave? When they collaborate? I need to learn about this, do they try to keep us consistent schedule, you're all awake at the same time,"
Andrej Karpathy said "I'm going to do try to create a routine. And I tried to create a steady state in which I'm comfortable. And so I have a morning routine, I have a daily routine, I tried to keep things through steady state, and things are predictable. And then you can sort of just like your body just sort of like sticks to that. And if you tried to stress that a little too much, it will create a you know, when you're traveling and you're dealing with jetlag, you're not able to really ascend to, you know where you need to go."
Lex Fridman said "Yeah, yeah, that's humans with the habits and stuff. What are your thoughts on work life balance throughout a human lifetime? So that same part was known for pushing people to their limits, in terms of what they're able to do in terms of what they're trying to do in terms of how much they work, all that kind of stuff? Yeah,"
Andrej Karpathy said "I mean, I will say test like, it's all too much bad rep for this, because what's happening is Tesla is a it's a bursty environment. So I would say the baseline, my only point of reference is Google, or like, where I've interned three times, and I saw what it's like inside Google and DeepMind. I would say the baseline is higher than that. But then there's a punctuated equilibrium, where once in a while, there's a fire. And some, like, people work really hard. And so it's spiky, and bursty. And then all the stories get collected upon the bursts. And then it gives the appearance of like, total insanity, but actually, it's just a bit more intense environment. And there are fires and sprints. And so I think, you know, it definitely though I, I would say it's a more intense environment than something you would get,"
Lex Fridman said "like you're in your person, forget all that. Just in your own personal life. What do you think about the happiness of a human being a brilliant person like yourself, about finding a balance between work and life? Or is it such a thing? Not a good thought experiment? Yeah, I think"
Andrej Karpathy said "I think balance is good. But I also love to have Sprint's that are out of distribution. And that's when I think I've been pretty creative. And as well"
Lex Fridman said "Sprint's out of distribution means that most of the time you have a, quote, unquote, balance, I have balanced most of the time. I like being obsessed with something once in a while, once in a while, is once a week, once a month, once a year, yeah, probably like, say, once a month or something. Yeah. And that's when we get a new GitHub repo from, that's when"
Andrej Karpathy said "you're, like, really care about a problem that must exist, this will be awesome. You're obsessed with it. And now you can't just do it on that day, you need to pay the fixed cost of getting into the groove. And then you need to stay there for a while. And then society will come and they will try to mess with you and they will try to distract you. Yeah, yeah, the worst thing is like a person who's like, I just need five minutes of your time. Yeah, this is the cost of that is not five minutes, and society needs to change how it thinks about just five minutes of your time. Right?"
Lex Fridman said "It's never it's never just one minute, just just 30 This is just a quick idea. Why are you being so ya know? What's your computer setup? What was like the perfect? Do I use somebody that's flexible to no matter? What laptop for screens? Yeah. Or do you prefer a certain setup that you're most productive?"
Andrej Karpathy said "Um, I guess the one that I'm familiar with is one large screen 27 inch, and my laptop on the side, what operating system? I do, Max, that's my primary for all tasks. I would say OS X. But when you're working on deep learning, everything is Linux. You're SSH into a cluster, and you're working remotely."
Lex Fridman said "But what about the actual development like using the ID,"
Andrej Karpathy said "you would use? I think a good way is you just run VS code. My favorite editor right now on your Mac, but you are actually you have a remote folder through SSH. So the actual files that you're manipulating are on the cluster somewhere else."
Lex Fridman said "So what's the best IDE VS code? What else do people use? So I use Emacs? Still? Let's go. It may be cool. I don't know if it's maximum product. tivity so what do you recommend in terms of editors? You worked a lot of software engineers, editors for Python, C++, machine learning applications."
Andrej Karpathy said "I think the current answer is VS code. Currently, I believe that's the best IDE. It's got a huge amount of extensions. It has GitHub copilot integration, which I think is very valuable."
Lex Fridman said "What do you think about the copilot integration? I was actually I got to talk a bunch with Guido van Rossum was the creator of Python. And he loves cocoa, you like programs a lot with it? Do you?"
Andrej Karpathy said "Yeah, he's copilot. I love it. And it's free for me, but I would pay for it. Yeah, I think it's very good. And the utility that I found with it was isn't isn't, I would say there's a learning curve. And you need to figure out when it's helpful and when to pay attention to its outputs. And when it's not going to be helpful, where you should not pay attention to it. Because if you're just reading it suggestions all the time, it's not a good way of interacting with it. But I think I was able to sort of like mold myself to it, I find it very helpful number one in copy, paste and replace some parts. So when the pattern is clear, it's really good at completing the pattern. And number two, sometimes it suggests API's that I'm not aware of. So it tells you about something that you didn't know. So and that's an opportunity to discover and use an opportunity to see I would never take a pilot code as given I almost always copy a copy paste into a Google search, and you see what this function is doing? And then you're like, oh, it's actually actually exactly what I need. Thank you copilot. So you learn something. So"
Lex Fridman said "it's in part a search engine apart? Maybe getting the exact syntax correctly that once you see it. Yeah, it's that NP hard things. Once you see it, you know, yes, exact correct. Exactly what you yourself can vary. You can verify efficiently, but you can't generate efficiently"
Andrej Karpathy said "and copilot really, I mean, it's it's autopilot for programming, right? And currently is doing the link following which is like the simple copy, paste and sometimes suggest, but over time, it's going to become more and more autonomous. And so the same thing will play out in not just coding, but actually across many, many different things. Probably"
Lex Fridman said "coding is an important one, right? writing programs. What how do you see the future that developing the program synthesis, like being able to write programs that are more and more complicated? Because right now, it's human supervised? in interesting ways? Yes. Like, what it feels like the transition will be very painful."
Andrej Karpathy said "My mental model for it is the same thing will happen to us with the autopilot, also currently is doing the following is doing some simple stuff. And eventually, we'll be doing autonomy and people will have to intervene less and less."
Lex Fridman said "And those could be like you like testing mechanisms. Like if a writes a function, and that function looks pretty damn correct. But how do you know it's correct? Because you're like getting lazier and lazier as a programmer, like your ability to know because like little bugs, but it gets it won't make a little noise."
Andrej Karpathy said "Well, it copilot will make our off by one subtle bugs. It has done that to me. But do you"
Lex Fridman said "think future systems will? Or is it really the off by one is actually a fundamental challenge of programming."
Andrej Karpathy said "In that case, it wasn't fundamental, and I think things can improve. But I think humans have to supervise. I am nervous about people not supervising what comes out. And what happens to for example, the proliferation of bugs in all of our systems. I'm nervous about that. But I think there will probably be some other copilots for bug finding and stuff like that at some point. So there'll be like a lot more automation for"
Lex Fridman said "man. It's like a program, a copilot that generates a compiler. One that does a linter Yes, one that does like a type checker. Yeah."
Andrej Karpathy said "It's a committee you have like a GPT serve, like, and then"
Lex Fridman said "there'll be like a manager for the committee. Yeah. And then there'll be somebody that says a new version of this as needed, we need to regenerate it."
Andrej Karpathy said "Yeah, there were 10 deputies that were forwarded and get 50 suggestions. And other one looked at it and pick the few that they like a bug one looked at it. And it was like it's probably a bug that got re ranked by some other thing. And then a final ensemble GPT comes in, it's like okay, given everything you guys have told me, this is probably the next token."
Lex Fridman said "You know, the feeling is the number of programmers in the world has been growing and growing very quickly. Do you think it's possible that it will actually level out and drop to like a very low number will this kind of world because then you'll be doing software 2.0 programming. And you'll be doing this kind of generation of copilot type systems programming, but you won't be doing the old school, Song software 1.0 program."
Andrej Karpathy said "I don't currently think that they're just going to replace human programmers. I'm so hesitant saying stuff like this, right? Because"
Lex Fridman said "this is going to be replaced in five years. I don't know it's going to show that like this is where we thought that because I agree with you, but I think we might be very surprised. Right? Like, what what are the next i What's your sense of where we stand on language models like does it feel like the beginning or the middle or the end the beginning?"
Andrej Karpathy said "100% I think the big part In my mind is for sure GPT will be able to program quite well competently and so on. How do you steer the system, you still have to provide some guidance to what you actually are looking for. And so how do you steer it? And how do you say how do you talk to it? How do you audit it and verify that what is done is correct. And how do you like work with this? And it's as much not just an AI problem, but a UI UX problem? Yeah. So beautiful, fertile ground for so much interesting work for vs. Code plus, plus where you're not just it's not just human programming anymore. It's amazing."
Lex Fridman said "Yeah. So you're interacting with the system. So not just one prompt. But it's iterative prompting, Yeah, we tried to figure out having a conversation with the system. Yeah. That I mean, to me, that's super exciting to have a conversation with the program I'm running."
Andrej Karpathy said "Yeah, maybe at some point you're just conversing with, it's like, Okay, here's what I want to do. Actually, this variable. Maybe it's not even that low level is variable. But"
Lex Fridman said "you can also imagine, like, can you translate this to C++ and back to Python? Already? Kind of existence? No, but just like doing it as part of the programming experience? Like, I think I'd like to write this function in C++. Or like, you just keep changing for different different programs, because the different syntax syntax, maybe I want to convert this into a functional language. Yeah. So like, you get to become multilingual, as a programmer, and dance back and forth efficiently. Yeah."
Andrej Karpathy said "I mean, I think the UI UX fit though, is like still very hard to think through. Because it's not just about writing code on a page, you have an entire developer environment, you have a bunch of hardware on it. You have some environmental variables, you have some scripts that are running in a cron job, like there's a lot going on to like working with computers, and how do these systems, set up environment flags and work across multiple machines and set up screen sessions and automate different processes like how that works, and is auditable by humans and so on is like, massive question on my mind. You've built"
Lex Fridman said "archive sanity, what is archive, and what is the future of academic research publishing that you would like to see."
Andrej Karpathy said "So archive is this preprint server. So if you have a paper, you can submit it for publication to journals or conferences, and then wait six months, and then maybe get a decision pass or fail, or you can just upload it to archive. And then people can tweet about it three minutes later, and then everyone sees it, everyone reads it, and everyone can profit from it in their own ways, and you can cite"
Lex Fridman said "it. And it has an official look to it. It feels like a pub. Like it feels like a publication process. Yeah, it feels different than if you just put it in a blog post."
Andrej Karpathy said "Oh, yeah. Yeah, I mean, it's a paper. And usually the bar is higher for something that you would expect on archive, as opposed to something you would see in a blog post,"
Lex Fridman said "or the culture created the bar, because you could probably guess, host a pretty crappy fix for an archive. So what was that make you feel like? What was that make you feel about peer review? So rigorous peer review by two, three experts versus the peer review of the community? Right, as it's written? Yeah,"
Andrej Karpathy said "basically, I think the community is very well able to peer review things very quickly on Twitter. And I think maybe it just has to do something with AI machine learning field specifically, though, I feel like things are more easily auditable. And the verification is easier, potentially, than the verification somewhere else. So it's kind of like, you can think of these scientific publications, there's like little blockchains, where everyone's building on each other's work and setting each other. And you sort of have AI, which is kind of like this much faster and loose blockchain. But then you have any one individual entry is like, very, very cheap to make. And then you have other fields where maybe that model doesn't make as much sense. And so I think in AI, at least things are pretty easily verifiable. And so that's why when people upload papers are a really good idea on so on, people can try it out the next day. And they can be the final arbiter of whether it works or not on their problem. And the whole thing just moves significantly faster. So I kind of feel like academia still has a place sort of dislike conference, journal process still has a place. But it's sort of like an it lags behind, I think, and it's a bit more maybe higher quality process. But it's not sort of the place where you will discover cutting edge work anymore. Yeah, it used to be the case when I was starting my PhD, that you go to conferences and journals, and you discuss all the latest research. Now when you go to a conference or journal like no one discusses anything that's there, because it's already like three generations ago. Irrelevant."
Lex Fridman said "Yes, it was. It makes me sad about like DeepMind, for example, where they still they still publish in nature. And these big, prestigious, I mean, there's still value I suppose, to the prestige that comes with these venues. But the result is that they they will announce some breakthrough performance. And it will take like a year to actually publish the details. I mean, and those details, if they will publish immediately will inspire the community to move in certain directions with it. Yeah, let's"
Andrej Karpathy said "speed up the rest of the community. But I don't know to what extent that's part of their objective function also."
Lex Fridman said "Sure. It's not just the prestige a little bit of the delay is is part"
Andrej Karpathy said "yeah, they certainly DeepMind specifically has been Working in the regime of having slightly higher quality, basically process and latency and publishing those papers that way."
Lex Fridman said "Another question from Reddit, do you or have you suffered from impostor syndrome being the director of AI Tesla, being this person, when you're at Stanford where like the world looks at you, as the expert in AI to teach, teach the world about machine learning."
Andrej Karpathy said "When I was leaving Tesla, after five years, I spent a ton of time in meeting rooms. And, you know, I would read papers in the beginning, when I joined Tesla, I was writing code, and then I was writing less and less code, and I was reading code, and then I was reading less and less code. And so this is just natural progression that happens, I think, and definitely, I would say, near the tail end, that's when it sort of starts to hit you a bit more that you're supposed to be an expert. But actually, the source of truth is the code that people are writing the GitHub and the actual, the actual code itself. And you're not as familiar with that as he used to be. And so I would say, maybe there's some like insecurity there."
Lex Fridman said "And that's actually pretty profound, that a lot of the insecurity has to do with not writing the code in the computer science base like that, because that is the truth that there is a code is"
Andrej Karpathy said "the source of truth, the papers and everything else, it's a high level summary, I don't know, just a high level summary. But at the end of the day, you have to read code, it's impossible to translate all that code into actual, you know, paper form. So when when things come up, especially when they have a source code available, that's my favorite place to go."
Lex Fridman said "So like I said, you're one of the greatest teachers of machine learning AI ever, from ces 231. End to today. What advice would you give to beginners interested in getting into machine learning,"
Andrej Karpathy said "beginners are often focused on like, what to do. And I think the focus should be more like how much you do. So I'm kind of like believer on the high level, and this 10,000 hours kind of concept, where you just kind of have to just pick the things where he can spend time and you care about and you're interested in, you literally have to put in 10,000 hours of work. It doesn't even like matter as much like where you put it, and you're, you'll iterate and you'll improve, and you'll waste some time, I don't know if there's a better way, you need to put in 10,000 hours. But I think it's actually really nice, because I feel like there's some sense of determinism about being an expert at a thing, if you spend 10,000 hours, you can literally pick an arbitrary thing. And I think if you spend 10,000 hours of deliberate effort and work, you actually will become an expert at it. And so I think it's kind of like a nice thought. And so basically, I would focus more on like, are you spending 10,000 hours and focus on"
Lex Fridman said "so and then thinking about what kind of mechanisms maximize your likelihood of getting to 10,000 hours exactly, which, for us, silly humans means probably forming a daily habit of like, every single day actually doing the thing,"
Andrej Karpathy said "whatever helps you. So I just think to a large extent, is a psychological problem for yourself. One other thing that I hope that I think is helpful for the psychology of it is many times people compare themselves to others in the area, I think it's very harmful. Only compare yourself to you from some time ago. Like, say, a year ago, are you better than you year ago, is the only way to think. And I think this then you can see your progress. And it's very motivating. And it's"
Lex Fridman said "so interesting, that focus on the quantity of hours, because I think a lot of people in the beginner stage but actually throughout get paralyzed by the choice like which one? Do I pick this path or this path? Yeah. Like, they'll literally get paralyzed by like, which ID to use?"
Andrej Karpathy said "Well, they're worried, yeah, they'll worried about all these things. But the thing is, some of you will waste time doing something wrong. Yes, you will eventually figure out it's not right, you will accumulate scar tissue. And next time, you'll grow stronger, because next time, you'll have the scar tissue. And next time, you'll learn from it. And now next time you come to a similar situation, you'll be like, Oh, I, I messed up. I've spent a lot of time working on things that never materialized into anything. And I have all that scar tissue. And I have some intuitions about what was useful, what wasn't useful, how things turned out. So all those mistakes where we're not dead work, you know, so I just think you shouldn't be here. Just focus on working. What have you done? What have you done last week?"
Lex Fridman said "That's a good question, actually, to ask for a lot of things that just machine learning. It's a good way to cut the, the way I forgot what the term we use, but the fluff the blob, or whatever the the inefficiencies in life. What do you love about teaching? You seem to find yourself often in the, like, drawn to teaching, you're very good at it, but you're also drawn to it."
Andrej Karpathy said "I mean, I don't think I love teaching. I love happy humans. And how humans live when I teach. I wouldn't say I hate teaching. I tolerate teaching, but it's not like the act of teaching that I like it's, it's that, you know, I have some I have something I'm actually okay at it. Yes, I'm okay at teaching and people appreciate it a lot. Yeah. And so I'm just happy to try to be helpful. And teaching itself is not like the most. I mean, it's really, it's can be really annoying, frustrating. I was working on a bunch of lectures just now. I was reminded back to my days of 31 and just how much work it is to create some of these materials to make them good. The amount of iteration and thought and you go down blind alleys and just how much you change it. So creating something good in terms of like educational value is really hard. And it's not fun"
Lex Fridman said "was difficult. So people should definitely go watch in new stuff you put their lectures, we actually building the thing like from, like you said the code is truth. So discussing backpropagation by building it by looking through it and just the whole thing. So how difficult is that to prepare for? That's a really powerful way to teach. How did you have to prepare for that? Are you just live thinking through it,"
Andrej Karpathy said "I will typically do like, say three takes, and then I take like, the better take. So I do multiple takes, and I take some of the better takes and then I just build out a lecture that way. Sometimes I have to delete 30 minutes of content, because it just went down an alley that I've been like too much. There's a bunch of iteration. And it probably takes me, you know, somewhere around 10 hours to create one hour of content"
Lex Fridman said "to give one hour. It's interesting. I mean, is it difficult to go back to the basics? Do you draw a lot of like wisdom from going back to the basics? Yeah,"
Andrej Karpathy said "going back to back propagation loss functions, where they come from. And one thing I like about teaching a lot, honestly, is it definitely strengthens your understanding. So it's not a purely altruistic activity, it's a way to learn. If you have to explain something to someone, you realize you have gaps in knowledge. And so I even surprised myself in those lectures, like, oh, the results will obviously look at this, and then the result doesn't look like it. And I'm like, Okay, I thought I understood this."
Lex Fridman said "That's why it's really cool to literally code, you run it in a notebook, and it gives you a result, and you're like, oh, wow, yes, like actual numbers, actual input, actual code that's not"
Andrej Karpathy said "mathematical symbols, etc. The source of truth is the code. It's not slides. It's just like, Let's build it."
Lex Fridman said "It's beautiful. You're rare human in that sense? What advice would you give to researchers trying to develop and publish idea that have a big impact in the world of AI? So maybe undergrads, maybe early graduate students?"
Andrej Karpathy said "Yep. I mean, I would say like, they definitely have to be a little bit more strategic than I had to be as a PhD student, because of the way AI is evolving. It's going the way of physics where, you know, in physics, he used to be able to do experiments on your benchtop. And everything was great. And you can make progress. And now you have to work in like LHC, or like CERN, and, and so AI is going in that direction as well. So there's certain kinds of things it's just not possible to do on the benchtop anymore. And I think that didn't used to be the case. At the time,"
Lex Fridman said "do you still think that there's like, gan type papers to be written, where like, like, very simple idea that requires just one computer to illustrate a simple example. I mean,"
Andrej Karpathy said "one example that's been very influential recently is diffusion models. The future models are amazing. Diffusion models are six years old. For the longest time, people are kind of ignoring them, as far as I can tell. And they're an amazing generative model, especially in images. And so stable diffusion and so on. It's all diffusion based, diffusion is new, it was not there and came from, well, it came from Google, but a researcher could have come up with it. In fact, some of the first actually know those came from Google as well. But a researcher could come up with that in an academic institution."
Lex Fridman said "Yeah. What do you find most fascinating about diffusion models? So from the societal impact of the technical"
Andrej Karpathy said "architecture, what I like about the fusion is it works so well."
Lex Fridman said "It was surprising to the amount of the variety, almost the novelty of the synthetic data is generating,"
Andrej Karpathy said "yes. So the stable diffusion images are incredible. It's the speed of improvement in generating images has been insane. We went very quickly from generating like, tiny digits to little tiny faces, and it all looked messed up. And now we were stable diffusion. And that happened very quickly. There's a lot that academia can still contribute, you know, for example, on flash attention is a very efficient kernel for running the attention operation inside the transformer that came from an academic environment. It's a very clever way to structure the kernel that does the calculation. So it doesn't materialize the attention matrix. And so there's I think there's still like lots of things to contribute, but you have to be just more strategic."
Lex Fridman said "Do you think neural networks can be made to reason?"
Andrej Karpathy said "Oh, yes."
Lex Fridman said "Do you think there already reason? Yes. What's your definition of reasoning?"
Andrej Karpathy said "Information processing."
Lex Fridman said "So the way that humans think through a problem and come up with novel ideas. It feels like reasoning. Yeah. So the novelty that I don't want to say but out of distribution ideas, you think is"
Andrej Karpathy said "possible? Yes. And I think we're seeing that already in the current neural nets. You're able to remix the training set information into true generalization in some sense, that doesn't appear it doesn't insert them into a training set. Like you're doing something interesting algorithmically. you're manipulating, you know, some symbols and you're coming up with I'm correct a unique answer in a new setting,"
Lex Fridman said "what would illustrate to you Holy shit, this thing is definitely thinking."
Andrej Karpathy said "To me thinking or reasoning is just information processing and generalization. And I think the neural nets already do that today."
Lex Fridman said "So being able to perceive the world or perceive the whatever the inputs are, and to make predictions based on that, or actions based on that that's that's reason, yeah, you're"
Andrej Karpathy said "giving correct answers in novel settings. By manipulating information, you've learned to correct algorithm. You're not doing just some kind of a lookup table and nearest neighbor search."
Lex Fridman said "Let me ask you about AGI. What are some moonshot ideas you think might make significant progress towards AGI? And maybe another way is, what are the big blockers that we're missing now?"
Andrej Karpathy said "So basically, I'm fairly bullish on our ability to build AGI is basically automated systems that we can interact with, and are very human like, and we can interact with them in the digital realm or physical realm. Currently, it seems most of the models that sort of do these sort of magical tasks are in a text realm. I think, as I mentioned, I'm suspicious that text realm is not enough to actually build full understanding of the world, I do actually think you need to go into pixels and understand the physical world and how it works. So I do think that we need to extend these models to consume images and videos and train on a lot more data that is multimodal in that way."
Lex Fridman said "Do you think you need to touch the world to understand also?"
Andrej Karpathy said "Well, that's the big open question I would say in my mind is if you also require the embodiment and the ability to sort of sort of interact with the world run experiments and have a data of that form, then you need to go to optimists, or something like that. And so I would say optimist in some way as like a hedge in AGI because it seems to me that it's possible that just having data from the internet is not enough. If that is the case, then optimists may lead to AGI because optimists were I, to me, there's nothing beyond Optimus, you have like this humanoid form factor that can actually like do stuff in the world, you can have millions of them interacting with humans and so on. And if that doesn't give rise to AGI at some point, like, I'm not sure what will. So from a completeness perspective, I think that's the, that's a really good platform. But it's a much harder platform, because you are dealing with atoms, and you need to actually like build these things and integrate them into society. So I think that path takes longer, but it's much more certain. And then there's a path of the internet and just like training these compression models effectively, on trying to compress all the internet. And that might also give these agents as well"
Lex Fridman said "compress the internet, but also interact with the Internet. So it's not obvious to me. In fact, I suspect you can reach AGI without ever entering the physical world. And then, which is a little bit more concerning because it might that results in it happening faster. So it just feels like we're in again, boiling water, we won't know as it's happening. I would like to, I'm not afraid of AGI. I'm excited about it. There's always concerns, but I would like to know when it happens. Yeah. Oh, and have like hints about when it happens, like a year from now. It will happen that kind of thing. Yeah, I just feel like in the digital realm, it just might happen. Yeah,"
Andrej Karpathy said "I think all we have available to us because no one has built AGI again. So all we have available to us is Is there enough fertile ground on the periphery? I would say yes. And we have the progress so far, which has been very rapid. And there are next steps that are available. And so I would say yeah, it's quite likely that we'll be interacting with digital"
Lex Fridman said "entities. How will you know that somebody has built a Jeep it's"
Andrej Karpathy said "going to be a slow I think it's going to be a slow incremental transition is going to be product based and focus is going to be GitHub copilot getting better. And then GPT is helping you right and then these Oracle's that you can go to with mathematical problems. I think we're on the on the verge of being able to ask very complex questions in chemistry, physics, math of these Oracle's and have them complete solutions."
Lex Fridman said "So AGI to us primarily focus on intelligence, so consciousness doesn't enter into into it."
Andrej Karpathy said "So in my mind, consciousness is not a special thank you will, you will figure out and bolt on. I think it's an emergent phenomenon of a large enough and complex enough generative model, sort of. So if you have a complex enough world model that understands the world, then it also understands its predicament in the world as being a language model, which to me is a form of consciousness or self awareness. And"
Lex Fridman said "so in order to understand the world deeper, you probably have to integrate yourself into the world and in order to interact with humans and other living beings. Consciousness is a very useful"
Andrej Karpathy said "tool. I think consciousness is like a modeling insight. Modeling insight. Yeah, it's a, you have a powerful enough model of understanding the world that you actually understand that you are an entity in it. Yeah. But"
Lex Fridman said "there's also this, perhaps just the narrative, we tell ourselves, there's a, it feels like something to experience the world, the hard problem of consciousness. But that could be just the narrative that we tell ourselves. Yeah, I don't"
Andrej Karpathy said "think I think it will emerge, I think it's going to be something very boring. Like, we'll be talking to these digital AIS, they will claim their conscious, they will appear conscious, they will do all the things that you would expect of other humans. And it's going to just be a stalemate."
Lex Fridman said "I think there'll be a lot of actual, fascinating ethical questions, like Supreme Court level questions of whether you're allowed to turn off a conscious AI, if you're allowed to build a conscious AI, maybe there would have to be the same kind of debates that you have around. Sorry, to bring up a political topic. But you know, abortion, which is a deeper question with abortion, is what is life? And the deep question with AI is also what is life and what is conscious, and I think that'll be very fascinating. To bring up, it might become illegal to build systems that are capable, that like, have such level of intelligence, that consciousness would emerge, and therefore the capacity to suffer will emerge? And some system that says, no, please don't kill me."
Andrej Karpathy said "Well, that's what the lambda compute the lambda chatbot already told, this Google engineer, right, like it was talking about not wanting to die, or so on. So that"
Lex Fridman said "might become illegal to do that, right. Because otherwise, you might have a lot of a lot of creatures that don't want to die, and they will"
Andrej Karpathy said "respond to someone cluster."
Lex Fridman said "And then that might lead to like horrible consequence, because then there might be a lot of people that secretly love murder, and they'll start practicing murder. And those systems mean, there's just, to me, all of this stuff just brings a beautiful mirror to the human condition. And human nature will get to explore it. And that's what like the best of the Supreme Court of all the different debates we have about ideas of what it means to be human, we get to ask those deep questions that we'll be asking, throughout human history, there has always been the other in human history, where the good guys and that's the bad guys, and we'll go on to, you know, throughout human history, let's murder the bad guys. And the same will probably happen with robots, it'll be the other at first, and then we'll get to ask questions, and what does it mean to be alive? What does it mean to be conscious?"
Andrej Karpathy said "And I think there's some canaries in the coal mines, even with what we have today. Um, and, you know, like, for example, these there's these like, why foods that you like to work with, and some people are trying to, like, this company is going to shut down but this person really like? Yeah, love their why foo and, like, strange, like ported somewhere else? And like, it's not possible. And like, I think, like, definitely, people will have feelings towards towards these systems, because in some sense, they are like a mirror of humanity. Because they are like, sort of like a big average of humanity in the way that it's trained"
Lex Fridman said "it but we can, that average, we can actually watch. And it's nice to be able to interact with the big average of humanity. Yeah. And do like a search query on it."
Andrej Karpathy said "Yeah, that's very fascinating. And we can also, of course, also like, shape it, it's not just a pure average, we can mess with the training data, we can mess with the objective, we can fine tune them in various ways. So we have some impact on what those systems look like,"
Lex Fridman said "if you want to achieve AGI. And you could have a conversation with her and ask her talk about anything, maybe ask her a question what what kind of stuff would you would you ask?"
Andrej Karpathy said "I would have some practical questions in my mind, like, do I or my loved ones really have to die? What can we do about that?"
Lex Fridman said "Do you think it will answer clearly? Or would it answer poetically,"
Andrej Karpathy said "I would expect it to give solutions, I would expect to be like, Well, I've read all of these textbooks, and I know all these things that you've produced. And it seems to me like here are the experiments that I think it would be useful to run next. And here's some gene therapies that I think would be helpful. And here are the kinds of experiments that you should run. Okay,"
Lex Fridman said "let's go with this thought experiment. Okay. Imagine that. Mortality is actually like our prerequisite for happiness. So if we become a mortal, we'll actually become deeply unhappy. And the model is able to know that. So what is it supposed to tell you stupid human about it? Yes, you can become a mortal, but you will become deeply unhappy. If the model is if the AGI system is trying to empathize with you human What is it supposed to tell you? That yes, you don't have to die but you're really not going to like it. Because you're going to be deeply honest. Like there As a Interstellar, what is it? The AI says like, humans want 90% Honesty. So like you have to pick how Honesdale want to answer these practical questions. Yeah,"
Andrej Karpathy said "I love AI. Interstellar, by the way, I think it's like such a sidekick to the entire story. But at the same time, it's like really interesting."
Lex Fridman said "It's kind of limited in certain ways, right? Yeah, it's"
Andrej Karpathy said "limited. And I think that's totally fine. By the way, I don't think I think it's fine implausible to have a limited and imperfect AGI is,"
Lex Fridman said "is that the feature almost"
Andrej Karpathy said "as an example, like it has a fixed amount of compute on its physical body. And it might just be that even though you can have a super amazing mega brain, super intelligent AI equals can have like, you know, less intelligent AI so you can deploy in a power efficient way. And then they're not perfect. They might make mistakes. No, I"
Lex Fridman said "meant more like, say you had infinite compute. And it's still good to make mistakes sometimes. Like in order to integrate yourself like, what is it going back to Goodwill Hunting, Robin Williams character says, like the human imperfections, that's the good stuff, right? Isn't it? Isn't that the, like, we don't want perfect, we want flaws, in part, to form connections with each other. Because it feels like something you can attach your feelings to the flaws in that same way you want an AI that's flawed. I don't know. I feel like perfectionist, but then you're saying okay, yeah. Well, that's not AGI But see, AGI would need to be intelligent enough to give answers to humans that humans don't understand. And I think perfect is something humans can understand. Because even science doesn't give perfect answers. There's always gaps and mysteries. And I don't know, I don't know if humans want perfect."
Andrej Karpathy said "Yeah, I can imagine just having a conversation with this kind of Oracle entity, as you'd imagine them. And yeah, maybe I can tell you about, you know, based on my analysis of human condition, you might not want this, and here are some of the things that might matter."
Lex Fridman said "But every, every dumb human will say yeah, trust me, I can give me the truth. I can handle it."
Andrej Karpathy said "But that's the beauty like people can choose"
Lex Fridman said "also. But then the old marshmallow test with the kids and so on, I feel like too many people. Like, can't handle the truth, probably including myself, like the deep truth of the human condition. I don't I don't know if I can handle it. Like, what is there some darks? What if we are an alien science experiment? And it realizes that what if it had? Yeah,"
Andrej Karpathy said "um, this is the matrix? You know, the nature again?"
Lex Fridman said "I don't know. I would, what would I talk about? I don't even Yeah, I probably I will go with the safe for scientific questions that first that have nothing to do with my own personal life. Yeah. And mortality, just like ball physics and so on. Yeah. To build up. Let's see words that are maybe see if it has a sense of humor. That's another question. Would it be able to, presumably in order to if it understands humans deeply would able to generate? To generate humor?"
Andrej Karpathy said "Yeah, I think that's actually a wonderful benchmark, almost like is it able? I think that's a really good point, basically, to make you laugh. Yeah. If it's able to be like a very effective stand up comedian that is doing something very interesting computationally. I think being funny is extremely hard."
Lex Fridman said "Yeah. Because it's hard in a way, like a Turing test. The original intent of the Turing test is hard. Because you have to convince humans, and there's nothing as what? That's what when comedians talk about this, like, there's this is deeply honest. Because if people can't help but laugh, and if they don't laugh, that means you're not funny. They laugh. That's funny. And you're showing"
Andrej Karpathy said "you need a lot of knowledge to create to create humor, about the automation, human condition, and so on. And then you need to be clever with it."
Lex Fridman said "You mentioned a few movies, you tweeted movies that I've seen five plus times, but I'm ready and willing to keep watching interstellar gladiator contact Goodwill Hunting the matrix, Lord of the Rings, or three avatar fifth elements on it goes on to marry to Mean Girls, I'm not going to ask about"
Andrej Karpathy said "man girls is great."
Lex Fridman said "What are some of the jump out to your memory that you love? In why, like you mentioned the matrix is a computer person. Why do you love the matrix?"
Andrej Karpathy said "There's so many properties that make it look beautiful, interesting. So there's all these philosophical questions, but then there's also a GIS, and there's simulation, and it's cool. And there's, you know, the black hole, you know, the look of it, the feel of it, the feel of it, the action, the bullet time, it was just like innovating in so many ways."
Lex Fridman said "And then goodwill Goodwill Hunting, why do you like that one?"
Andrej Karpathy said "Yeah, I just I really liked this tortured genius sort of character who's like, grappling with whether or not he has like, any responsibility or like what to do with this gift that he was given or like how to think about the whole thing. And"
Lex Fridman said "there's also dance between the genius and the personal, like, what it means to love another human being. And there's a lot of things there is just a beautiful movie, and then the fatherly figure, the mentor in the psychiatrist and it like, really,"
Andrej Karpathy said "like, it messes with you, you know, there's some movies that just like really mess with you. on a deep level,"
Lex Fridman said "do you relate to that movie at all? No, it's like I said, Lord of the Rings, it's self explanatory. Terminator two, which is interesting. You rewatch that? Oh, there's that better than Terminator one? You like, you're like Terminator"
Andrej Karpathy said "one as well. I like Terminator two a little bit more. But in terms of like its surface properties."
Lex Fridman said "I do you think Skynet is at all a possibility? Yes. Like the actual sort of autonomous weapon system kind of thing? Do you worry about that stuff? I do worry, I use a war."
Andrej Karpathy said "I 100% worry about it. And so the I mean, the, you know, some of these fears of AGI and how this will pan out. I mean, these will be like very powerful entities, probably at some point. And so for a long time, they're going to be tools in the hands of humans. You know, people talk about like, alignment of AGI and how to make the problem is like even humans are not aligned. So how this will be used? And what this is going to look like it's yes, troubling. So do you"
Lex Fridman said "think it'll happen slowly, slowly enough that we'll be able to, as a human civilization, think through the problems? Yes,"
Andrej Karpathy said "that's my hope is that it's happened slowly enough, and an open enough way where a lot of people can see and participate in it. Just figure out how to deal with this transition? I think it was kind of interesting,"
Lex Fridman said "I draw a lot of inspiration from nuclear weapons, because I sure thought it would be would be fucked once would they develop nuclear weapons. But like, it's almost like, when, when the systems are not so dangerous, they destroy human civilization, we deploy them and learn the lessons. And then we quickly if it's too dangerous, we'll quickly quickly we might still deploy it. But you'll very quickly learn not to use them. And so there'll be like this balance that you humans are very clever as a species. It's interesting. We exploit the resources as much as we can, but we don't we avoid destroying ourselves, it seems like,"
Andrej Karpathy said "well, I don't know about that actually,"
Lex Fridman said "hope it continues."
Andrej Karpathy said "I mean, I'm definitely like concerned about nuclear weapons, and so on, not just as a result of the recent conflict, even before that, that's probably my number one concern for facility."
Lex Fridman said "So if humanity destroys itself, or destroys, you know, 90% of people that would be because of nukes?"
Andrej Karpathy said "I think so. And it's not even about full destruction. To me, it's bad enough. If we reset society, that would be like, terrible. It'd be really bad. And I can't believe we're, like, so close to it. Yeah, it's like so crazy. To me."
Lex Fridman said "It feels like we might be a few tweets away from something like that."
Andrej Karpathy said "Yep. Basically, it's extremely unnerving. But and has been for me for a long time."
Lex Fridman said "It seems unstable, that world leaders just having a bad mood, can like, take one step towards a bad direction and it escalates. Yeah, because of a collection of bad moods, it can escalate without being able to stop."
Andrej Karpathy said "Yeah, it's just it's a huge amount of power. And then also with the proliferation of basically I don't, I don't actually really see, I don't actually know what the good outcomes are here. So I'm definitely worried about that a lot. And then AGI is not currently there. But I think at some point will more and more become something like it. The danger with AGI even is that I think it's even less likely worse in the sense that there are good outcomes of AGI. And then the bad outcomes are like an epsilon away, like a tiny one away. And so I think capitalism and humanity and so on will drive for the positive ways of using that technology. But then if bad outcomes are just like a tiny, like flip a minus sign away. That's a really bad position to be in"
Lex Fridman said "a tiny perturbation of the system results in the destruction of the human species. So weird line to walk."
Andrej Karpathy said "Yeah, I think in general, what's really weird about like the dynamics of humanity, and this explosion we've talked about is just like being st coupling afforded by technology, and just the instability of the whole dynamical system. I think it just doesn't look good. Honestly."
Lex Fridman said "Yes, that exclusion can be destructive or constructive and the probabilities are nonzero and both"
Andrej Karpathy said "I'm gonna have to, I do feel like I have to try to be optimistic and so on. And yes, I think even in this case, I still am predominantly optimistic, but there's definitely"
Lex Fridman said "me too. Do you think we'll become a multiplanetary species?"
Andrej Karpathy said "Probably yes. But I don't know. If it's dominant feature of future humanity, there might be some people on some planets and so on. But I'm not sure if it's like, yeah, if it's like a major player in our culture and so on,"
Lex Fridman said "we still have to solve the drivers of self destruction here on Earth. So just having a backup on Mars is not going to solve the problem."
Andrej Karpathy said "So by the way, I love the backup on Mars. I think that's amazing. You should absolutely do that. Yes. And, um, so would you? Or would you go to Mars? Personally, no, I do like Earth quite a lot. I'll go"
Lex Fridman said "to Mars, I'll go. I'll tweet at you from"
Andrej Karpathy said "maybe eventually, I would, once it's safe enough. But I don't actually know if it's on my lifetime scale, unless I can extend it by a lot. I do think that, for example, a lot of people might disappear into virtual realities and stuff like that. And I think that could be the major thrust of sort of the cultural development of humanity, if it survives. So it might not be, it's just really hard to work in physical realm, and go out there. And I think ultimately, all your experiences are in your brain. And so it's much easier to just disappear into the digital realm. And I think people will find them more compelling, easier, safer, more interesting."
Lex Fridman said "So you're a little bit captivated by virtual reality where the possible worlds where there's the metaverse or some other manifestation of that, yeah. Yeah, it's really interesting. And so I'm interested just just talking a lot to Carmack. Where's the? Where's the thing that's currently preventing that? Yeah,"
Andrej Karpathy said "I want to be clear, I think what's interesting about future is, it's not that I kind of feel like the variance in the human condition, gross, that's the primary thing that's changing, it's not as much the mean, of the distribution is like the variance of it. So there will probably be people in Mars, and there will be people in VR, and there will be people here on Earth. It's just like, there'll be so many more ways of being. And so I kind of feel like I see it as like a spreading out of the human experience."
Lex Fridman said "There's something about the internet that allows you to discover those little groups and gravitate to something about your biology likes that kind of world that you find each other,"
Andrej Karpathy said "and we'll have transhumanists and then we'll have the Amish and they're gonna, everything is just going to coexist."
Lex Fridman said "You know, the cool thing about it, because I've interacted with a bunch of Internet communities is they don't know about each other. Like, you can have a very happy existence, just like having a very close knit community and not knowing about each other. We even use consensus just having traveled to Ukraine. There's they don't know so many things about America, you like when you travel across the world, they think you experienced this, too. They're certain cultures, they're like they have their own thing going on. They don't. So you can see that happening more and more and more and more in the future. We are a little communities. Yeah."
Andrej Karpathy said "Yeah, I think so that seems to be the that seems to be how it's going right now. And I don't see that trend, like really reversing. I think people are diverse, and they're able to choose their own, like path in existence. And I sort of like celebrate that. And so we you spend"
Lex Fridman said "so much time in the metaverse in the virtual reality, or which community area is a physicalist? The physical reality enjoyer? Or do you see drawing a lot of pleasure and fulfillment in the digital world?"
Andrej Karpathy said "Yeah, I think currently, the virtual reality is not that compelling. I do think it can improve a lot. But I don't really know to what extent, maybe you know, there's actually like even more exotic things you can think about with like neural links or stuff like that. So currently, I kind of see myself as mostly a team, human person. I love nature. I love harmony. I love people. I love humanity. I love emotions of humanity. And I just want to be like in this like solar punk little utopia. That's my happy place is my happy place is like, people I love thinking about cool problems surrounded by lush, beautiful, dynamic nature, and secretly high tech in places that count"
Lex Fridman said "places like they use technology to empower that love for other humans and nature."
Andrej Karpathy said "Yeah, I think that's technology used like very sparingly. I don't love when it sort of gets in the way of humanity in many ways. I like just people being humans in the way we sort of like, slightly evolved and prefer I think, just by default, people kept"
Lex Fridman said "asking me because they know you love reading? Are there particular books that you enjoyed that had an impact on you? For silly or for profound reasons that you recommend? You mentioned the vital question."
Andrej Karpathy said "Many, of course, I think in biology as an example, the vital question is a good one. Anything by MacLean, really, life ascending, I would say is like a bit more potentially representative as like a summary of a lot of the things he's been talking about. I was very impacted by The Selfish Gene. I thought that was a really good book that helped me understand altruism as an example and where it comes from and just realizing that you know, the selection is on the level of genes was a huge insight for me at the time, and it's sort of like cleared up a lot of things for me."
Lex Fridman said "What do you think about the the idea that Ideas are the organisms, the meetups?"
Andrej Karpathy said "Love it 100%?"
Lex Fridman said "Are you able to walk around with that notion for a while that, that there is an evolutionary kind of process with ideas as well? There absolutely"
Andrej Karpathy said "is. There's memes just like genes and they compete, and they live in our brains. That's beautiful."
Lex Fridman said "Are we silly humans thinking that we're the organisms? Is it possible that the primary organisms are the ideas?"
Andrej Karpathy said "Yeah, I would say like the the ideas kind of live in the software, or of like our civilization, in the, in the minds and so on."
Lex Fridman said "We think as humans that the hardware is the fundamental thing. I human is a hardware entity. Yeah. But it could be the software. Right? Yeah."
Andrej Karpathy said "Yeah, I would say like, there needs to be some grounding at some point to like a physical reality."
Lex Fridman said "Clone and Andrej the software is the thing. Like, is this thing that makes that thing special? Right? Yeah, I guess you're right. But then cloning might be exceptionally difficult. Like there might be a deep integration between the software and the hardware in which we don't quite understand"
Andrej Karpathy said "or from the origin point of view, like what makes me special is more like the the gang of genes that are writing in my chromosomes, I suppose. Right? Like they're the replicating unit, I suppose. And"
Lex Fridman said "no, but that's just deliver you the thing that makes you special? Sure. Well, the reality is, what makes you special is your ability to survive, based on the software that runs on the hardware that was built by the genes. So the software is the thing that makes you survive, not the hardware. All right."
Andrej Karpathy said "It's a little bit of both. It's just like a second layer. It's a new second layer that hasn't been there before the brain. They both they both coexist, but"
Lex Fridman said "there's also layers of the software. I mean, it's it's not it's a so abstractions, on top of abstractions,"
Andrej Karpathy said "but okay, so so selfish gene. And McLean, I would say sometimes, books are like not sufficient. I like to reach for textbooks, sometimes. I kind of feel like books are for too much of a general consumption sometime. And they just kind of like they're too high up in the level of abstraction. And it's not good enough. Yeah. So I like textbooks. I like it the cell, I think the cell was pretty cool. That's why also I like the writing of Nick lane is because he's pretty willing to step one level down. And he doesn't get he sort of he's willing to go there. But he's also willing to sort of be throughout the stack. So he'll go down to a lot of detail, but then he will come back up. And I think he has a biscuit. I really appreciate that."
Lex Fridman said "That's why I love college, early college, even high school, just textbooks on the basics of Computer Science and Mathematics of biology of chemistry. Yes, those are they condensed down. Like it's sufficiently general, they can understand the both the philosophy and the details, but also like you get homework problems, and you get to play with it as much as you would if you were in programming stuff."
Andrej Karpathy said "Yeah. And then I'm also suspicious of textbooks, honestly, because, as an example, in deep learning, there's no like amazing textbooks and the field is changing very quickly. I imagine the same is true and say, synthetic biology and so on. These books like the cell are kind of outdated, they're still high level, like, what is the actual real source of truth? It's people in wet labs, working with cells, you know, sequencing genomes, and yeah, actually working with working with it. And I don't have that much exposure to that, or what that looks like. So I still don't fully I'm reading through the cell. And it's kind of interesting, and I'm learning but it's still not sufficient, I would say in terms of understanding"
Lex Fridman said "what it's a clean summarization of the mainstream narrative. Yeah, but you have to learn that before you break out. Yeah. At the, towards the cutting edge."
Andrej Karpathy said "Yeah. What is the actual process of working with the cells and growing them and incubating them and, you know, it's kind of like a massive cooking recipes and making sure yourself slows and proliferate. And then you're sequencing them running experiments. And just how that works, I think is kind of like the source of truth of at the end of the day, what's really useful in terms of creating therapies and so on."
Lex Fridman said "Now, what are in the future AI textbooks will be because, you know, there's artificial intelligence, a modern approach. Actually, I haven't read if it's come out the recent version, the recent, there's been a recent addition. I also saw there's a size of deep learning book, I'm waiting for textbooks that worth recommending worth reading. Yeah, it's tricky. Because it's like papers, and code code code. Honestly,"
Andrej Karpathy said "papers are quite good. I especially like the appendices appendix of any paper as well. It's like, it's like the most detail can have."
Lex Fridman said "It doesn't have to be cohesive, connected. Anything else. You just described me very specific ways on to particular thing Yeah,"
Andrej Karpathy said "many times papers can be actually quite readable. Not always. But sometimes the introduction in the abstract is readable even for someone outside of the field. Not this is not always true. And sometimes I think unfortunately, scientists use complex terms even when it's not necessary. I think that's harmful. I think there's no reason for that."
Lex Fridman said "And the papers, sometimes they're longer than they need to be in this in the parts that don't matter. Yeah, Appendix would be long. But then the papers of you know, look at Einstein make it simple."
Andrej Karpathy said "Give us only I've come across papers, I would say, say like synthetic biology or something that I thought were quite reasonable for the abstract and the introduction, and then you're reading the rest of it. And you don't fully understand, but you kind of are getting a gist. And I think it's cool."
Lex Fridman said "What advice you give advice to folks interested in machine learning and research, but in general life advice to young person high school, early college about how to have a career that can be proud of or life that can be proud of?"
Andrej Karpathy said "Yeah, I think I'm very hesitant to give general advice. I think it's really hard. I've mentioned like some of the stuff I've mentioned, is fairly general, I think, like focus on just the amount of work you're spending on like a thing. Compare yourself to only to yourself, not to others. That's good. I think those are fairly general,"
Lex Fridman said "how do you pick the thing?"
Andrej Karpathy said "You just have like a deep interest in something. Or like, try to like find the arg max over like, the things that you're interested in arg max"
Lex Fridman said "at that moment, and stick with it? How do you not get distracted? And switch to another thing?"
Andrej Karpathy said "You can if you like,"
Lex Fridman said "we, if you do an arg max repeatedly, every week"
Andrej Karpathy said "doesn't converge? It's a problem. Yeah, you can like low pass filter yourself in terms of like, what has consistently been true for you. But yeah, I definitely see how it can be hard. But I would say like, you're going to work the hardest on the thing that you care about the most. So low pass filter yourself and really introspect in your past are the things that gave you energy? And what are the things that took that energy away from you concrete examples. And usually, from those concrete examples, sometimes parents can emerge. I like I like it when things look like this, when I'm these positions. That's not"
Lex Fridman said "necessarily the field, but the kind of stuff you're doing in a particular field. So for you, it seems like you were energized by implementing still building actual things."
Andrej Karpathy said "Yeah, being low level learning, and then also communicating so that others can go through the same realizations and shortening that gap. Because I usually have to do way too much work to understand a thing. And then I'm like, Okay, this is actually like, Okay, I think I get it, and like, why was it so much work? It should have been much less work. And that gives me a lot of frustration. And that's why I sometimes go teach."
Lex Fridman said "So aside from the teaching, you're doing now, putting our videos, aside from a potential Godfather Part Two, with the AGI at Tesla and beyond? What is the future for Andrej Karpathy hold? Have you figured that out yet? Or no? I mean, as you see through the fog of war, that is all of our future? Do you start seeing silhouettes of what that possible future could look like?"
Andrej Karpathy said "The consistent thing I've been always interested in, for me, at least is AI. And that's probably where I'm spending my the rest of my life on, because I just care about it a lot. And actually care about like many other problems as well, like, say, aging, which I basically view as disease. And I care about that as well. But I don't think it's a good idea to go after it. Specifically, I don't actually think that humans will be able to come up with the answer, I think the correct thing to do is to ignore those problems, and you solve AI, and then use that to solve everything else. And I think there's a chance that this will work, I think it's a very high chance. And that's kind of like the, the way I'm betting at least"
Lex Fridman said "so when you think about AI, are you interested in all kinds of applications, all kinds of domains, and any domain you focus on will allow you to get insights. Now the big problem of AGI"
Andrej Karpathy said "here for me is the ultimate meta problem. I don't want to work on any one specific problem, there's too many problems. So how can you work on all problems simultaneously? You solved the meta problem, which to me is just intelligence and how do you automate it? Is there"
Lex Fridman said "cool small projects like archive sanity, and, and so on that you're thinking about the, the world the ML world can anticipate."
Andrej Karpathy said "There's some always like some fun side projects. Archives sanity is one of the basically like, there's way too many archive papers, how can I organize it and recommend papers and so on? I transcribed all of your podcasts,"
Lex Fridman said "what did you learn from that experience? From transcribing the process of like you like consuming audiobooks and podcasts and so on? Anyway, here's the process that achieves closer to human level performance on meditation. Yeah,"
Andrej Karpathy said "well, I definitely was like surprised that transcription with opening eyes whisper was working so well, compared to what I'm familiar with from Siri and like a few other systems. I guess. It works so well. And that's what gave me some energy to like, try it out. And I thought it could be fun to random podcasts. It's kind of not obvious to me why whisper is so much better compared to anything else? Because I feel like there should be a lot of incentive for a lot of companies to produce transcription systems and that they've done so over a long time. Whisper is not a super exotic model. It's a transformer. It takes Mel spectrograms and, you know, just outputs tokens of texts, not crazy. The model and everything has been around for a long time. I'm not actually 100% sure why"
Lex Fridman said "you Not it's not obvious to me either. It makes me feel like I'm missing something. I'm missing something. Yeah. Because there's a huge move in Google and so on YouTube transcription. Yeah. Yeah, it's unclear, but some of it is also integrating into a bigger system. Yeah, that is, so the user interface, how's deployed all that kind of stuff, maybe running it as an independent thing is eat much easier, like an order of magnitude easier than deploying to a large integrated system, like YouTube transcription or anything like meetings, Zoom has transmit transcription. That's kind of crappy. But creating an interface where the text the different individual speakers, it's able to display it in compelling ways run in real time, all that kind of stuff. Maybe that's difficult. That's the only explanation I have. Because like, I'm currently paying quite a bit for human transcription, human caption, right annotation. Like, it seems like there's a huge incentive to automate that. Yeah. It's very confusing, I"
Andrej Karpathy said "think. I mean, I don't know if you'd looked at some of the Whisper transcripts, but they're quite good."
Lex Fridman said "They're good. And especially in tricky cases, I've seen whispers performance on like, super tricky cases. And it does incredibly well. So I don't know, a podcast is pretty simple. It's like high quality audio, and you're speaking usually pretty clearly. So I don't know it. I don't know what open as plans are. Yeah, either."
Andrej Karpathy said "But yeah, there's always like fun, fun projects, basically. And stable diffusion also is opening up a huge amount of experimentation, I would say in the visual realm, and generate generating images and videos and movies, like videos now. And so that's going to be pretty crazy, that's going to that's going to almost certainly work. And it's going to be really interesting when the cost of content creation is going to fall to zero. He used to need a painter for a few months to paint a thing. And now he's going to be speak to your phone to get your video."
Lex Fridman said "So Hollywood will start using that to generate scenes. Which completely opens up. Yeah, so you can make like a movie like Avatar, eventually, for under a million dollars,"
Andrej Karpathy said "much less maybe just by talking to your phone? I mean, I know it sounds kind of crazy."
Lex Fridman said "And then there'll be some voting mechanism, like how do you have an like, will there be a show on Netflix as generated completely? Automatically?"
Andrej Karpathy said "So naturally? Yeah. And what does it look like also, when you can just generate on demand? And it's, and there's infinity of it? Yeah."
Lex Fridman said "All the synthetic art. I mean, it's humbling because we treat ourselves as special for being able to generate art and ideas and all that kind of stuff. If that can be done in an automated way, by AI."
Andrej Karpathy said "Yeah. I think it's fascinating to me how these, the predictions of AI and what it's going to look like and what's going to be capable of are completely inverted and wrong. And sci fi of 50s and 60s was just like, totally not right. Imagine AI is like, super calculating theory improvers. And we're getting things that can talk to you about emotions, it can do art. It's just like weird."
Lex Fridman said "Are you sad about that future just has, like, hybrid systems, heterogeneous systems of humans and AIS talking about emotions, Netflix and chill with an AI system. Legit word. The Netflix thing you watch is also generated by AI."
Andrej Karpathy said "I think it's a it's going to be interesting for sure. And I think I'm cautiously optimistic, but it's not it's not obvious. Well, the"
Lex Fridman said "sad thing is your brain and mine developed in a time where before Twitter before the before the internet, so I wonder people that are born inside of it might have a different experience? Like I maybe you can, will still resist it. And the people born now will not?"
Andrej Karpathy said "Well, I do feel like humans are extremely malleable. Yeah. And you're probably right."
Lex Fridman said "What is the meaning of life? Andre? We talked about sort of the universe having a conversation with us humans are would the systems we create to try to answer for the universe? For the creator of the universe to notice us? We're trying to create systems that are allowed enough. Just answer back."
Andrej Karpathy said "I don't know if that's the meaning of life. That's like meaning of life. For some people. The first level answer I would say is anyone can choose their own meaning of life because we are conscious entity and it's beautiful. Number one, but I do think that like a deeper meaning of life, if someone is interested, is are along the lines of like, What the hell is Elvis? And like why? And if you look at the into fundamental physics and the quantum field theory in the Standard Model, they're like, we're very complicated. And there's this like 19 free primer parameters of our universe. And like, what's going on with all this stuff? And why is it here and can I hack it? Can I work? with it, is there a message for me? Am I supposed to create a message? And so I think there's some fundamental answers there. But I think there's actually even like, you can't actually really make a dent in those without more time. And so to me also, there's a big question around just getting more time, honestly. Yeah, that's kind of like what I think about quite a bit as well."
Lex Fridman said "So kind of the ultimate, or at least first way to sneak up to the why. Question is to try to escape the system, the universe, and then for that, you sort of backtrack and say, okay, for that, that's going to be take a very long time. So the wide question boils down from an engineering perspective to how do we extend? Yeah, I"
Andrej Karpathy said "think that's the question number one, practically speaking, because you can't, you're not going to calculate the answer to the deeper questions in time you have."
Lex Fridman said "And that could be extending your own lifetime or extending just the lifetime of human civilization"
Andrej Karpathy said "of whoever wants to not many people might not want that. But I think people who do want that, I think, I think it's probably possible. And I don't think I don't know that people fully realize this. I kind of feel like people think of death as an inevitability. But at the end of the day, this is a physical system, some things go wrong. It makes sense why things like this happen, evolutionarily speaking. And there's most certainly interventions that that mitigate it."
Lex Fridman said "That'd be interesting. If death is eventually looked at as, as a fascinating thing that used to happen to humans. I don't"
Andrej Karpathy said "think it's unlikely. I think it's, I think it's likely."
Lex Fridman said "And it's up to our imagination to try to predict what the world without death looks like. Yeah, it's hard to, I think the values will completely change."
Andrej Karpathy said "To be, I don't, I don't really buy all these ideas that Oh, without that there's no meaning. There's nothing as I don't intuitively by all those arguments, I think there's plenty of meaning plenty of things to learn. They're interesting, exciting, I want to know, I want to calculate, I want to improve the condition of all the humans and organisms that are alive."
Lex Fridman said "The way we find meaning might change. We there is a lot of humans, probably including myself, that finds meaning in the finiteness of things. But that doesn't mean that's the only source of meaning."
Andrej Karpathy said "Yeah, I think many people will, will go with that, which I think is great. I love the idea that people can just choose their own adventure. Like you, you are born as a conscious free entity, by default, I like to think and you have your unalienable rights for life. In the"
Lex Fridman said "pursuit of happiness, proceed, I don't know. The nature the landscape of happiness,"
Andrej Karpathy said "and you can choose your own adventure mostly. And that's not fully true, but"
Lex Fridman said "I still am pretty sure I'm an NPC, but an NPC can't know it's an NPC. There could be different degrees and levels of consciousness. I don't think there's a more beautiful way tended. Andrea, you're an incredible person. I'm really honored. You would talk with me, everything you've done for the machine learning world for the AI world, to just inspire people to educate millions of people. It's been, it's been great. I can't wait to see what you do next. It's been an honor. Man, thank you so much for talking to that. Awesome. Thank you. Thanks for listening to this conversation with Andrej Karpathy. To support this podcast. Please check out our sponsors in the description. And now let me leave you with some words from Samuel Carlin. The purpose of models is not to fit the data, but to sharpen the questions. Thanks for listening and hope to see you next time."
